import streamlit as st
import pandas as pd
import numpy as np
import joblib
import pickle
import matplotlib.pyplot as plt
import sys
import io
import base64
from datetime import datetime
import seaborn as sns
import re
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="PDRé£é™©é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ‘ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# === æ ¸å¿ƒå®šä¹‰ï¼šä»…ä¿ç•™20ä¸ªæ ¸å¿ƒç‰¹å¾ ===
# ä¸­è‹±æ–‡ç‰¹å¾æ˜ å°„å­—å…¸
FEATURE_MAPPING = {
    # åŸºæœ¬ä¿¡æ¯
    'æ€§åˆ«': 'Sex',
    'å¹´é¾„': 'Age',
    'ç³–å°¿ç—…ç—…ç¨‹': 'Course',
    'BMI': 'BMI',
    'è…°è‡€æ¯”': 'WHR',
    'æ”¶ç¼©å‹': 'SBP',
    'èˆ’å¼ å‹': 'DBP',
    'é«˜è¡€å‹ç—…ç¨‹': 'duration of HT',
    # å®éªŒå®¤æŒ‡æ ‡
    'è¡€å°¿ç´ æ°®': 'BUN',
    'è¡€æ¸…è‚Œé…': 'Scr',
    'å°¿é…¸': 'UA',
    'æ€»è›‹ç™½': 'TP',
    'ç™½è›‹ç™½': 'ALB',
    'æ€»èƒ†çº¢ç´ ': 'TBIL',
    'ç›´æ¥èƒ†çº¢ç´ ': 'DBIL',
    'è°·ä¸™è½¬æ°¨é…¶': 'ALT',
    'è°·è‰è½¬æ°¨é…¶': 'AST',
    'ç©ºè…¹è¡€ç³–': 'FBG',
    'ç³–åŒ–è¡€çº¢è›‹ç™½': 'HbA1c',
    'å°¿ç™½è›‹ç™½æ’æ³„ç‡': 'UAER'
}

# åå‘æ˜ å°„ï¼ˆè‹±æ–‡åˆ°ä¸­æ–‡ï¼‰
REVERSE_FEATURE_MAPPING = {v: k for k, v in FEATURE_MAPPING.items()}

# ç‰¹å¾åˆ†ç»„
FEATURE_GROUPS = {
    'basic': {
        'name': 'åŸºæœ¬ä¿¡æ¯',
        'features': ['æ€§åˆ«', 'å¹´é¾„', 'ç³–å°¿ç—…ç—…ç¨‹', 'BMI', 'è…°è‡€æ¯”', 'æ”¶ç¼©å‹', 'èˆ’å¼ å‹', 'é«˜è¡€å‹ç—…ç¨‹']
    },
    'advanced': {
        'name': 'å®éªŒå®¤æŒ‡æ ‡',
        'features': ['è¡€å°¿ç´ æ°®', 'è¡€æ¸…è‚Œé…', 'å°¿é…¸', 'æ€»è›‹ç™½', 'ç™½è›‹ç™½', 'æ€»èƒ†çº¢ç´ ', 'ç›´æ¥èƒ†çº¢ç´ ',
                     'è°·ä¸™è½¬æ°¨é…¶', 'è°·è‰è½¬æ°¨é…¶', 'ç©ºè…¹è¡€ç³–', 'ç³–åŒ–è¡€çº¢è›‹ç™½', 'å°¿ç™½è›‹ç™½æ’æ³„ç‡']
    }
}

# å¼ºåˆ¶å®šä¹‰20ä¸ªæ ¸å¿ƒç‰¹å¾ï¼ˆè‹±æ–‡ï¼‰
CORE_FEATURES_EN = [
    'Sex', 'Age', 'Course', 'BMI', 'WHR', 'SBP', 'DBP', 'duration of HT',
    'BUN', 'Scr', 'UA', 'TP', 'ALB', 'TBIL', 'DBIL', 'ALT', 'AST', 'FBG', 'HbA1c', 'UAER'
]

# æ•°å€¼å‹ç‰¹å¾ï¼ˆæ³¨æ„ï¼šæ€§åˆ«æ˜¯åˆ†ç±»å‹ï¼Œå…¶ä»–éƒ½æ˜¯æ•°å€¼å‹ï¼‰
NUMERIC_FEATURES = [
    'Age', 'Course', 'BMI', 'WHR', 'SBP', 'DBP', 'duration of HT',
    'BUN', 'Scr', 'UA', 'TP', 'ALB', 'TBIL', 'DBIL', 'ALT', 'AST', 'FBG', 'HbA1c', 'UAER'
]
CATEGORICAL_FEATURES = ['Sex']


# === è¾“å…¥å­—æ®µåˆ›å»ºå‡½æ•° ===
def create_input_field_chinese(feature_name):
    """æ ¹æ®ä¸­æ–‡ç‰¹å¾ååˆ›å»ºè¾“å…¥å­—æ®µ"""
    if feature_name == 'æ€§åˆ«':
        options = [("å¥³æ€§", 2), ("ç”·æ€§", 1)]
        selected = st.selectbox("æ€§åˆ«", options=options, format_func=lambda x: x[0])
        return selected[1]
    elif feature_name == 'å¹´é¾„':
        return st.number_input("å¹´é¾„ï¼ˆå²ï¼‰", min_value=0, max_value=120, value=50, step=1)
    elif feature_name == 'ç³–å°¿ç—…ç—…ç¨‹':
        return st.number_input("ç³–å°¿ç—…ç—…ç¨‹ï¼ˆå¹´ï¼‰", min_value=0.0, max_value=50.0, value=5.0, step=0.5)
    elif feature_name == 'BMI':
        return st.number_input("BMIï¼ˆä½“é‡æŒ‡æ•°ï¼‰", min_value=10.0, max_value=50.0, value=24.0, step=0.1)
    elif feature_name == 'è…°è‡€æ¯”':
        return st.number_input("è…°è‡€æ¯”ï¼ˆWHRï¼‰", min_value=0.5, max_value=1.5, value=0.9, step=0.01)
    elif feature_name == 'é«˜è¡€å‹ç—…ç¨‹':
        return st.number_input("é«˜è¡€å‹ç—…ç¨‹ï¼ˆå¹´ï¼‰", min_value=0.0, max_value=50.0, value=0.0, step=0.5)
    elif feature_name == 'æ”¶ç¼©å‹':
        return st.number_input("æ”¶ç¼©å‹ï¼ˆmmHgï¼‰", min_value=60.0, max_value=250.0, value=120.0, step=1.0)
    elif feature_name == 'èˆ’å¼ å‹':
        return st.number_input("èˆ’å¼ å‹ï¼ˆmmHgï¼‰", min_value=40.0, max_value=150.0, value=80.0, step=1.0)
    elif feature_name == 'è¡€å°¿ç´ æ°®':
        return st.number_input("è¡€å°¿ç´ æ°®ï¼ˆBUN, mmol/Lï¼‰", min_value=1.0, max_value=30.0, value=5.0, step=0.1)
    elif feature_name == 'è¡€æ¸…è‚Œé…':
        return st.number_input("è¡€æ¸…è‚Œé…ï¼ˆScr, Î¼mol/Lï¼‰", min_value=20.0, max_value=500.0, value=70.0, step=1.0)
    elif feature_name == 'å°¿é…¸':
        return st.number_input("å°¿é…¸ï¼ˆUA, Î¼mol/Lï¼‰", min_value=100.0, max_value=800.0, value=300.0, step=1.0)
    elif feature_name == 'æ€»è›‹ç™½':
        return st.number_input("æ€»è›‹ç™½ï¼ˆTP, g/Lï¼‰", min_value=40.0, max_value=100.0, value=70.0, step=0.1)
    elif feature_name == 'ç™½è›‹ç™½':
        return st.number_input("ç™½è›‹ç™½ï¼ˆALB, g/Lï¼‰", min_value=20.0, max_value=60.0, value=45.0, step=0.1)
    elif feature_name == 'æ€»èƒ†çº¢ç´ ':
        return st.number_input("æ€»èƒ†çº¢ç´ ï¼ˆTBIL, Î¼mol/Lï¼‰", min_value=1.0, max_value=100.0, value=12.0, step=0.1)
    elif feature_name == 'ç›´æ¥èƒ†çº¢ç´ ':
        return st.number_input("ç›´æ¥èƒ†çº¢ç´ ï¼ˆDBIL, Î¼mol/Lï¼‰", min_value=0.0, max_value=50.0, value=4.0, step=0.1)
    elif feature_name == 'è°·ä¸™è½¬æ°¨é…¶':
        return st.number_input("è°·ä¸™è½¬æ°¨é…¶ï¼ˆALT, U/Lï¼‰", min_value=5.0, max_value=200.0, value=25.0, step=1.0)
    elif feature_name == 'è°·è‰è½¬æ°¨é…¶':
        return st.number_input("è°·è‰è½¬æ°¨é…¶ï¼ˆAST, U/Lï¼‰", min_value=5.0, max_value=200.0, value=26.0, step=1.0)
    elif feature_name == 'ç©ºè…¹è¡€ç³–':
        return st.number_input("ç©ºè…¹è¡€ç³–ï¼ˆFBG, mmol/Lï¼‰", min_value=3.0, max_value=30.0, value=6.5, step=0.1)
    elif feature_name == 'ç³–åŒ–è¡€çº¢è›‹ç™½':
        return st.number_input("ç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1c, %ï¼‰", min_value=4.0, max_value=15.0, value=6.5, step=0.1)
    elif feature_name == 'å°¿ç™½è›‹ç™½æ’æ³„ç‡':
        return st.number_input("å°¿ç™½è›‹ç™½æ’æ³„ç‡ï¼ˆUAER, Î¼g/minï¼‰", min_value=0.0, max_value=500.0, value=20.0, step=1.0)
    else:
        return st.number_input(f"{feature_name}", min_value=0.0, max_value=1000.0, value=50.0, step=1.0)


# === åŠ å¼ºç‰ˆæ•°æ®æ¸…æ´—å‡½æ•° ===
def clean_numeric_dataframe(df):
    """æ¸…æ´—æ•°å€¼æ•°æ®ï¼Œå¤„ç†ä¸­æ–‡é€—å·/ç©ºæ ¼/ç©ºå­—ç¬¦ä¸²"""
    df_clean = df.copy()

    for col in df_clean.columns:
        # å…ˆå°†æ•´ä¸ªåˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç„¶åè¿›è¡Œæ¸…æ´—
        df_clean[col] = df_clean[col].astype(str).apply(lambda x: x.strip() if isinstance(x, str) else x)

        # å¤„ç†ç©ºå­—ç¬¦ä¸²å’Œç©ºç™½å­—ç¬¦
        def clean_value(x):
            # å¦‚æœæ˜¯NaNæˆ–None
            if pd.isna(x):
                return np.nan

            # å¦‚æœæ˜¯å­—ç¬¦ä¸²
            if isinstance(x, str):
                x_str = x.strip()

                # å¦‚æœæ¸…æ´—åæ˜¯ç©ºå­—ç¬¦ä¸²
                if x_str == '':
                    return np.nan

                # å¤„ç†å¸¸è§çš„ä¸­æ–‡ç¬¦å·
                x_str = x_str.replace('ï¼Œ', '.').replace(',', '.').replace(' ', '')

                # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                try:
                    return float(x_str)
                except:
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•æå–æ•°å­—éƒ¨åˆ†
                    try:
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å­—ï¼ˆåŒ…æ‹¬å°æ•°ç‚¹å’Œè´Ÿå·ï¼‰
                        numbers = re.findall(r'-?\d+\.?\d*', x_str)
                        if numbers:
                            return float(numbers[0])
                        else:
                            return np.nan
                    except:
                        return np.nan
            # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
            return x

        df_clean[col] = df_clean[col].apply(clean_value)

    return df_clean


# === ä¸‹è½½é“¾æ¥å‡½æ•° ===
def get_table_download_link(df, filename="é¢„æµ‹ç»“æœ.xlsx", format="excel"):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    df_display = df.copy()
    # åˆ—åè½¬æ¢ä¸ºä¸­æ–‡
    column_mapping = {}
    for col in df_display.columns:
        if col in REVERSE_FEATURE_MAPPING:
            column_mapping[col] = REVERSE_FEATURE_MAPPING[col]
        elif col in ['PDRé¢„æµ‹æ¦‚ç‡', 'PDRé¢„æµ‹ç±»åˆ«', 'PDRé£é™©ç­‰çº§', 'é¢„æµ‹æ—¶é—´']:
            column_mapping[col] = col
    if column_mapping:
        df_display = df_display.rename(columns=column_mapping)

    if format == "excel":
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_display.to_excel(writer, index=False, sheet_name='é¢„æµ‹ç»“æœ')
        excel_data = output.getvalue()
        b64 = base64.b64encode(excel_data).decode()
        href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ (Excel)</a>'
    else:
        csv = df_display.to_csv(index=False, encoding='utf-8-sig')
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename.replace(".xlsx", ".csv")}">ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ (CSV)</a>'
    return href


# === æ¨¡å‹åŠ è½½å‡½æ•°ï¼ˆå…¼å®¹å¤„ç†ï¼‰ ===
@st.cache_resource
def load_model_and_preprocessors():
    """åŠ è½½æ¨¡å‹å’Œé¢„å¤„ç†å·¥å…·"""
    try:
        # åŠ è½½æ¨¡å‹
        model = joblib.load('final_results/lightgbm_pdr_model.pkl')

        # åŠ è½½scaler
        scaler = joblib.load('final_results/scaler.pkl')

        # å…³é”®ï¼šåŠ è½½å»ºæ¨¡æ—¶ä½¿ç”¨çš„imputers
        try:
            median_imputer = joblib.load('feature_selection_results/median_imputer.pkl')
            mode_imputer = joblib.load('feature_selection_results/mode_imputer.pkl')
        except:
            st.warning("âš ï¸ æœªæ‰¾åˆ°å»ºæ¨¡æ—¶çš„imputeræ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°çš„imputer")
            median_imputer = SimpleImputer(strategy='median')
            mode_imputer = SimpleImputer(strategy='most_frequent')

        # å°è¯•åŠ è½½selected_featuresï¼Œå¦‚æœæ²¡æœ‰å°±ä½¿ç”¨æ‰€æœ‰æ ¸å¿ƒç‰¹å¾
        try:
            selected_features = pd.read_csv('final_results/selected_features.csv').iloc[:, 0].tolist()
            # è¿‡æ»¤selected_featuresï¼Œä»…ä¿ç•™20ä¸ªæ ¸å¿ƒç‰¹å¾
            selected_features = [f for f in selected_features if f in CORE_FEATURES_EN]
        except:
            selected_features = CORE_FEATURES_EN

        # è·å–imputeræ‹Ÿåˆæ—¶çš„ç‰¹å¾é¡ºåº
        try:
            if hasattr(median_imputer, 'feature_names_in_'):
                imputer_numeric_features = list(median_imputer.feature_names_in_)
            else:
                imputer_numeric_features = NUMERIC_FEATURES
        except:
            imputer_numeric_features = NUMERIC_FEATURES

        try:
            if hasattr(mode_imputer, 'feature_names_in_'):
                imputer_categorical_features = list(mode_imputer.feature_names_in_)
            else:
                imputer_categorical_features = CATEGORICAL_FEATURES
        except:
            imputer_categorical_features = CATEGORICAL_FEATURES

        # ç‰¹å¾ä¿¡æ¯
        feature_info = {
            'numeric_features': NUMERIC_FEATURES,
            'categorical_features': CATEGORICAL_FEATURES,
            'feature_names': selected_features,
            'median_imputer': median_imputer,
            'mode_imputer': mode_imputer,
            'scaler': scaler,
            'imputer_numeric_features': imputer_numeric_features,
            'imputer_categorical_features': imputer_categorical_features
        }

        return model, scaler, feature_info, selected_features
    except Exception as e:
        st.error(f"åŠ è½½å¤±è´¥: {e}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None, None, None, None


# === é¢„å¤„ç†å‡½æ•°ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰ ===
def preprocess_batch_data(batch_df, feature_info, selected_features):
    """æ‰¹é‡æ•°æ®é¢„å¤„ç†ï¼ˆå¼ºåˆ¶å¯¹é½20ä¸ªæ ¸å¿ƒç‰¹å¾ï¼‰"""
    # 1. æ•°æ®æ¸…æ´—
    batch_df = clean_numeric_dataframe(batch_df)

    # 1.5 ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹ï¼ˆé™¤äº†æ€§åˆ«ï¼‰
    for col in batch_df.columns:
        if col != 'æ€§åˆ«' and col in batch_df.columns:
            # å°è¯•å°†åˆ—è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            batch_df[col] = pd.to_numeric(batch_df[col], errors='coerce')

    # 2. åˆ—åè½¬æ¢ï¼ˆä¸­æ–‡â†’è‹±æ–‡ï¼‰
    column_mapping = {}
    for col in batch_df.columns:
        col_clean = str(col).strip()
        if col_clean in FEATURE_MAPPING:
            column_mapping[col] = FEATURE_MAPPING[col_clean]
        elif col_clean in CORE_FEATURES_EN:
            column_mapping[col] = col_clean

    if column_mapping:
        batch_df = batch_df.rename(columns=column_mapping)

    # 3. æ˜¾ç¤ºæ£€æµ‹åˆ°çš„åˆ—
    detected_cols = list(batch_df.columns)
    st.info(f"âœ… æ£€æµ‹åˆ° {len(detected_cols)} ä¸ªç‰¹å¾åˆ—: {detected_cols}")

    # 4. æ£€æŸ¥ç¼ºå¤±çš„æ ¸å¿ƒç‰¹å¾
    missing_core = [col for col in CORE_FEATURES_EN if col not in batch_df.columns]
    if missing_core:
        missing_chinese = [REVERSE_FEATURE_MAPPING.get(col, col) for col in missing_core]
        st.warning(f"âš ï¸ ä»¥ä¸‹æ ¸å¿ƒç‰¹å¾ç¼ºå¤±ï¼Œå°†ç”¨é»˜è®¤å€¼å¡«å……: {missing_chinese}")

    # 5. å¼ºåˆ¶å¯¹é½20ä¸ªæ ¸å¿ƒç‰¹å¾ï¼ˆåªä¿ç•™éœ€è¦çš„ï¼Œç¼ºå¤±çš„åˆ—å¡«å……NaNï¼‰
    batch_df_aligned = pd.DataFrame(index=batch_df.index)

    for feature in CORE_FEATURES_EN:
        if feature in batch_df.columns:
            batch_df_aligned[feature] = batch_df[feature]
        else:
            # è®¾ç½®é»˜è®¤å€¼
            if feature == 'Sex':  # æ€§åˆ«
                batch_df_aligned[feature] = 2  # é»˜è®¤å¥³æ€§
            elif feature == 'Age':  # å¹´é¾„
                batch_df_aligned[feature] = 50  # é»˜è®¤50å²
            elif feature == 'BMI':  # BMI
                batch_df_aligned[feature] = 24.0  # é»˜è®¤æ­£å¸¸ä½“é‡
            else:
                batch_df_aligned[feature] = 0.0  # å…¶ä»–ç‰¹å¾é»˜è®¤0

    # 6. åˆ†ç¦»æ•°å€¼å‹/åˆ†ç±»å‹ç‰¹å¾
    numeric_data = batch_df_aligned[NUMERIC_FEATURES].copy()
    categorical_data = batch_df_aligned[CATEGORICAL_FEATURES].copy() if CATEGORICAL_FEATURES else pd.DataFrame()

    # 6.5 ç¡®ä¿æ•°å€¼æ•°æ®æ˜¯æ•°å€¼ç±»å‹ï¼ˆé˜²æ­¢å­—ç¬¦ä¸²æ±¡æŸ“ï¼‰
    for col in numeric_data.columns:
        numeric_data[col] = pd.to_numeric(numeric_data[col], errors='coerce')

    # 7. å¤„ç†æ€§åˆ«ç‰¹å¾ - ç¡®ä¿æ˜¯æ•´æ•°ç±»å‹
    if 'Sex' in categorical_data.columns:
        def convert_sex(x):
            if pd.isna(x):
                return 2

            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆå¤„ç†
            if isinstance(x, str):
                x_str = x.strip()
                if x_str == '':
                    return 2

                # å¤„ç†å¸¸è§æ€§åˆ«è¡¨ç¤º
                if x_str in ['1', 'ç”·', 'male', 'Male', 'M', '1.0', '1.00']:
                    return 1
                elif x_str in ['2', 'å¥³', 'female', 'Female', 'F', '2.0', '2.00']:
                    return 2
                else:
                    try:
                        val = int(float(x_str))
                        if val == 1:
                            return 1  # ç”·æ€§
                        else:
                            return 2  # å…¶ä»–å€¼é»˜è®¤ä¸ºå¥³æ€§
                    except:
                        return 2  # âœ… é»˜è®¤å¥³æ€§
            else:
                # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è½¬æ¢
                try:
                    val = int(float(x))
                    if val == 1:
                        return 1
                    else:
                        return 2
                except:
                    return 2

        categorical_data['Sex'] = categorical_data['Sex'].apply(convert_sex)

    # 8. å¡«å……ç¼ºå¤±å€¼ - ä½¿ç”¨å»ºæ¨¡æ—¶ä¿å­˜çš„imputers
    median_imputer = feature_info.get('median_imputer')
    mode_imputer = feature_info.get('mode_imputer')
    imputer_numeric_features = feature_info.get('imputer_numeric_features', NUMERIC_FEATURES)
    imputer_categorical_features = feature_info.get('imputer_categorical_features', CATEGORICAL_FEATURES)

    # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•
    st.info(f"ğŸ“Š æ•°å€¼æ•°æ®å½¢çŠ¶: {numeric_data.shape}")
    st.info(f"ğŸ“Š æ•°å€¼æ•°æ®ç±»å‹:\n{numeric_data.dtypes}")

    if median_imputer is not None:
        # ç¡®ä¿numeric_dataçš„é¡ºåºä¸imputeræ‹Ÿåˆæ—¶çš„é¡ºåºä¸€è‡´
        numeric_data_reordered = numeric_data.reindex(columns=imputer_numeric_features)

        # ä½¿ç”¨å»ºæ¨¡æ—¶çš„ä¸­ä½æ•°å¡«å……å™¨
        try:
            numeric_filled = median_imputer.transform(numeric_data_reordered)

            # è½¬æ¢å›DataFrameï¼Œä¿æŒåŸå§‹é¡ºåº
            numeric_data = pd.DataFrame(
                numeric_filled,
                columns=imputer_numeric_features,
                index=numeric_data.index
            ).reindex(columns=NUMERIC_FEATURES)

            st.info("âœ… ä½¿ç”¨å»ºæ¨¡æ—¶çš„ä¸­ä½æ•°å¡«å……æ•°å€¼å‹ç‰¹å¾")
        except Exception as e:
            st.error(f"âŒ ä¸­ä½æ•°å¡«å……å¤±è´¥: {e}")
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„ä¸­ä½æ•°å¡«å……
            st.warning("âš ï¸ ä½¿ç”¨ç®€å•ä¸­ä½æ•°å¡«å……")
            for col in numeric_data.columns:
                if numeric_data[col].isnull().any():
                    median_val = numeric_data[col].median()
                    numeric_data[col] = numeric_data[col].fillna(median_val)
    else:
        # å¦‚æœæ²¡æœ‰ä¿å­˜çš„imputerï¼Œåˆ›å»ºæ–°çš„
        st.warning("âš ï¸ æœªæ‰¾åˆ°å»ºæ¨¡æ—¶çš„ä¸­ä½æ•°å¡«å……å™¨ï¼Œå°†åˆ›å»ºæ–°çš„ä¸­ä½æ•°å¡«å……å™¨")
        for col in numeric_data.columns:
            if numeric_data[col].isnull().any():
                median_val = numeric_data[col].median()
                numeric_data[col] = numeric_data[col].fillna(median_val)

    if mode_imputer is not None and not categorical_data.empty:
        # ç¡®ä¿categorical_dataçš„é¡ºåºä¸imputeræ‹Ÿåˆæ—¶çš„é¡ºåºä¸€è‡´
        categorical_data_reordered = categorical_data.reindex(columns=imputer_categorical_features)

        # ä½¿ç”¨å»ºæ¨¡æ—¶çš„ä¼—æ•°å¡«å……å™¨
        try:
            categorical_filled = mode_imputer.transform(categorical_data_reordered)

            # è½¬æ¢å›DataFrameï¼Œä¿æŒåŸå§‹é¡ºåº
            categorical_data = pd.DataFrame(
                categorical_filled,
                columns=imputer_categorical_features,
                index=categorical_data.index
            ).reindex(columns=CATEGORICAL_FEATURES)

            st.info("âœ… ä½¿ç”¨å»ºæ¨¡æ—¶çš„ä¼—æ•°å¡«å……åˆ†ç±»å‹ç‰¹å¾")
        except Exception as e:
            st.error(f"âŒ ä¼—æ•°å¡«å……å¤±è´¥: {e}")
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„ä¼—æ•°å¡«å……
            st.warning("âš ï¸ ä½¿ç”¨ç®€å•ä¼—æ•°å¡«å……")
            for col in categorical_data.columns:
                if categorical_data[col].isnull().any():
                    mode_val = categorical_data[col].mode()[0] if not categorical_data[col].mode().empty else 2
                    categorical_data[col] = categorical_data[col].fillna(mode_val)
    elif not categorical_data.empty:
        # å¦‚æœæ²¡æœ‰ä¿å­˜çš„imputerï¼Œåˆ›å»ºæ–°çš„
        st.warning("âš ï¸ æœªæ‰¾åˆ°å»ºæ¨¡æ—¶çš„ä¼—æ•°å¡«å……å™¨ï¼Œå°†åˆ›å»ºæ–°çš„ä¼—æ•°å¡«å……å™¨")
        for col in categorical_data.columns:
            if categorical_data[col].isnull().any():
                mode_val = categorical_data[col].mode()[0] if not categorical_data[col].mode().empty else 2
                categorical_data[col] = categorical_data[col].fillna(mode_val)

    # 9. åˆå¹¶æ•°æ®
    processed_data = pd.concat([numeric_data, categorical_data], axis=1)

    # 10. æ ‡å‡†åŒ–æ•°å€¼å‹ç‰¹å¾ - ä½¿ç”¨å»ºæ¨¡æ—¶ä¿å­˜çš„scaler
    scaler = feature_info.get('scaler')
    if scaler is not None:
        try:
            # è·å–scaleræ‹Ÿåˆæ—¶çš„ç‰¹å¾é¡ºåº
            if hasattr(scaler, 'feature_names_in_'):
                scaler_features = list(scaler.feature_names_in_)
                # ç¡®ä¿numeric_dataçš„é¡ºåºä¸scaleræ‹Ÿåˆæ—¶çš„é¡ºåºä¸€è‡´
                numeric_data_for_scaling = numeric_data.reindex(columns=scaler_features)
                numeric_scaled = scaler.transform(numeric_data_for_scaling)
                numeric_scaled = pd.DataFrame(
                    numeric_scaled,
                    columns=scaler_features,
                    index=numeric_data.index
                ).reindex(columns=NUMERIC_FEATURES)
            else:
                # å¦‚æœæ²¡æœ‰ç‰¹å¾åç§°ï¼Œç›´æ¥ä½¿ç”¨
                numeric_scaled = pd.DataFrame(
                    scaler.transform(numeric_data),
                    columns=NUMERIC_FEATURES,
                    index=numeric_data.index
                )
            st.info("âœ… ä½¿ç”¨å»ºæ¨¡æ—¶çš„æ ‡å‡†åŒ–å™¨è¿›è¡Œæ ‡å‡†åŒ–")
        except Exception as e:
            st.error(f"âŒ æ ‡å‡†åŒ–å¤±è´¥: {e}")
            st.warning("âš ï¸ ä½¿ç”¨æ–°çš„æ ‡å‡†åŒ–å™¨")
            scaler_new = StandardScaler()
            numeric_scaled = pd.DataFrame(
                scaler_new.fit_transform(numeric_data),
                columns=NUMERIC_FEATURES,
                index=numeric_data.index
            )
    else:
        # å¦‚æœæ²¡æœ‰ä¿å­˜çš„scalerï¼Œåˆ›å»ºæ–°çš„
        st.warning("âš ï¸ æœªæ‰¾åˆ°å»ºæ¨¡æ—¶çš„æ ‡å‡†åŒ–å™¨ï¼Œå°†åˆ›å»ºæ–°çš„æ ‡å‡†åŒ–å™¨")
        scaler_new = StandardScaler()
        numeric_scaled = pd.DataFrame(
            scaler_new.fit_transform(numeric_data),
            columns=NUMERIC_FEATURES,
            index=numeric_data.index
        )

    processed_data[NUMERIC_FEATURES] = numeric_scaled

    # 11. ç¡®ä¿ç‰¹å¾é¡ºåºä¸æ¨¡å‹è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
    if selected_features:
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„ç‰¹å¾
        missing_features = [f for f in selected_features if f not in processed_data.columns]
        if missing_features:
            st.warning(f"âš ï¸ ä»¥ä¸‹æ¨¡å‹ç‰¹å¾ç¼ºå¤±ï¼Œå°†ç”¨0å¡«å……: {missing_features}")
            for feat in missing_features:
                processed_data[feat] = 0

        # é‡æ–°æ’åˆ—ç‰¹å¾é¡ºåºï¼Œç¡®ä¿ä¸æ¨¡å‹è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
        processed_data = processed_data.reindex(columns=selected_features)
        st.info(f"âœ… ç‰¹å¾é¡ºåºå·²è°ƒæ•´ä¸ºæ¨¡å‹è®­ç»ƒæ—¶çš„é¡ºåºï¼Œå…± {len(selected_features)} ä¸ªç‰¹å¾")

        # æ˜¾ç¤ºæœ€ç»ˆçš„ç‰¹å¾é¡ºåº
        with st.expander("ğŸ” æŸ¥çœ‹æœ€ç»ˆç‰¹å¾é¡ºåº"):
            st.write("æ¨¡å‹é¢„æµ‹æ—¶å°†ä½¿ç”¨çš„ç‰¹å¾é¡ºåº:")
            for i, feat in enumerate(selected_features, 1):
                chinese_name = REVERSE_FEATURE_MAPPING.get(feat, feat)
                st.write(f"{i}. {chinese_name} ({feat})")
    else:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šselected_featuresï¼Œä½¿ç”¨æ‰€æœ‰æ ¸å¿ƒç‰¹å¾
        processed_data = processed_data[CORE_FEATURES_EN]

    return processed_data, batch_df_aligned


# === æ‰¹é‡é¢„æµ‹å‡½æ•° ===
def batch_predict(batch_df, model, feature_info, selected_features):
    """æ‰¹é‡é¢„æµ‹"""
    # é¢„å¤„ç†
    processed_data, original_df = preprocess_batch_data(batch_df, feature_info, selected_features)

    if processed_data is None:
        return None

    # æ˜¾ç¤ºå¤„ç†åçš„æ•°æ®å½¢çŠ¶å’Œç‰¹å¾é¡ºåº
    st.info(f"ğŸ“Š å¤„ç†åæ•°æ®å½¢çŠ¶: {processed_data.shape}")
    st.info(f"ğŸ“Š ä½¿ç”¨çš„ç‰¹å¾æ•°é‡: {len(processed_data.columns)}")

    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®ç”¨äºè°ƒè¯•
    with st.expander("ğŸ” é¢„å¤„ç†åæ•°æ®é¢„è§ˆ"):
        st.dataframe(processed_data.head(), use_container_width=True)

    # é¢„æµ‹
    try:
        probabilities = model.predict_proba(processed_data)[:, 1]
        predictions = model.predict(processed_data)

        # é£é™©ç­‰çº§
        def get_risk_level(prob):
            if prob < 0.3:
                return "ä½é£é™©"
            elif prob < 0.7:
                return "ä¸­é£é™©"
            else:
                return "é«˜é£é™©"

        risk_levels = [get_risk_level(prob) for prob in probabilities]

        # ç»“æœæ•´åˆ
        results_df = original_df.copy()
        results_df['PDRé¢„æµ‹æ¦‚ç‡'] = probabilities
        results_df['PDRé¢„æµ‹ç±»åˆ«'] = predictions
        results_df['PDRé£é™©ç­‰çº§'] = risk_levels
        results_df['é¢„æµ‹æ—¶é—´'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        return results_df
    except Exception as e:
        st.error(f"é¢„æµ‹å‡ºé”™: {e}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None


# === å•æ‚£è€…é¢„æµ‹å‡½æ•° ===
def predict_single_patient(input_data_dict, model, feature_info):
    """å•æ‚£è€…é¢„æµ‹"""
    try:
        # è½¬æ¢ä¸ºè‹±æ–‡ç‰¹å¾å
        english_input = {}
        for chinese_feature, value in input_data_dict.items():
            if chinese_feature in FEATURE_MAPPING:
                english_input[FEATURE_MAPPING[chinese_feature]] = value

        # å¡«å……ç¼ºå¤±ç‰¹å¾çš„é»˜è®¤å€¼
        for feature in CORE_FEATURES_EN:
            if feature not in english_input:
                if feature == 'Sex':
                    english_input[feature] = 2
                elif feature == 'Age':
                    english_input[feature] = 50
                elif feature == 'BMI':
                    english_input[feature] = 24.0
                else:
                    english_input[feature] = 0.0

        # è½¬æ¢ä¸ºDataFrame
        input_df = pd.DataFrame([english_input], columns=CORE_FEATURES_EN)

        # é¢„å¤„ç†
        numeric_data = input_df[NUMERIC_FEATURES].copy()
        categorical_data = input_df[CATEGORICAL_FEATURES].copy()

        # é¢„å¤„ç†æ€§åˆ«
        if 'Sex' in categorical_data.columns:
            def convert_sex(x):
                if pd.isna(x):
                    return 2
                x_str = str(x).strip()
                if x_str in ['1', 'ç”·', 'male', 'Male', 'M']:
                    return 1
                elif x_str in ['2', 'å¥³', 'female', 'Female', 'F']:
                    return 2
                else:
                    try:
                        val = int(float(x_str))
                        if val == 1:
                            return 1
                        else:
                            return 2
                    except:
                        return 2  # âœ… å¥³æ€§

            categorical_data['Sex'] = categorical_data['Sex'].apply(convert_sex)

        # ä½¿ç”¨å»ºæ¨¡æ—¶ä¿å­˜çš„scalerè¿›è¡Œæ ‡å‡†åŒ–
        scaler = feature_info.get('scaler')
        if scaler is not None:
            numeric_scaled = scaler.transform(numeric_data)
            numeric_data = pd.DataFrame(numeric_scaled, columns=NUMERIC_FEATURES)
        else:
            # å¦‚æœæ²¡æœ‰ä¿å­˜çš„scalerï¼Œåˆ›å»ºæ–°çš„
            scaler_new = StandardScaler()
            numeric_scaled = scaler_new.fit_transform(numeric_data)
            numeric_data = pd.DataFrame(numeric_scaled, columns=NUMERIC_FEATURES)

        # åˆå¹¶æ•°æ®
        processed_data = pd.concat([numeric_data, categorical_data], axis=1)

        # ä½¿ç”¨æ¨¡å‹éœ€è¦çš„ç‰¹å¾å¹¶ç¡®ä¿é¡ºåºä¸€è‡´
        if 'feature_names' in feature_info and feature_info['feature_names']:
            selected_features = feature_info['feature_names']
            # ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½å­˜åœ¨
            for feat in selected_features:
                if feat not in processed_data.columns:
                    processed_data[feat] = 0
            # é‡æ–°æ’åˆ—ç‰¹å¾é¡ºåº
            processed_data = processed_data[selected_features]
        else:
            processed_data = processed_data[CORE_FEATURES_EN]

        # é¢„æµ‹
        probability = model.predict_proba(processed_data)[0][1]
        prediction = model.predict(processed_data)[0]

        return probability, prediction
    except Exception as e:
        st.error(f"é¢„æµ‹å‡ºé”™: {e}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None, None


# === ä¸»å‡½æ•° ===
def main():
    st.title("ğŸ‘ï¸ ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ï¼ˆPDRï¼‰é£é™©é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")

    # åŠ è½½æ¨¡å‹
    with st.spinner("åŠ è½½æ¨¡å‹ä¸­..."):
        model, scaler, feature_info, selected_features = load_model_and_preprocessors()

    if model is None:
        st.error("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥final_resultsç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶ï¼")
        return

    # æ£€æŸ¥imputeræ˜¯å¦åŠ è½½æˆåŠŸ
    if feature_info.get('median_imputer') is None or feature_info.get('mode_imputer') is None:
        st.warning("""
        âš ï¸ **æ³¨æ„**ï¼šæœªæ‰¾åˆ°å»ºæ¨¡æ—¶çš„å¡«å……å™¨æ–‡ä»¶
        - é¢„æµ‹æ—¶å°†ä½¿ç”¨å½“å‰æ•°æ®é‡æ–°è®¡ç®—ä¸­ä½æ•°/ä¼—æ•°
        - è¿™å¯èƒ½å¯¼è‡´ä¸å»ºæ¨¡æ—¶ä¸ä¸€è‡´ï¼Œå½±å“é¢„æµ‹å‡†ç¡®æ€§
        - è¯·ç¡®ä¿å°† `median_imputer.pkl` å’Œ `mode_imputer.pkl` æ”¾åœ¨ `feature_selection_results/` ç›®å½•ä¸‹
        """)

    # æ£€æŸ¥scaleræ˜¯å¦åŠ è½½æˆåŠŸ
    if feature_info.get('scaler') is None:
        st.warning("""
        âš ï¸ **æ³¨æ„**ï¼šæœªæ‰¾åˆ°å»ºæ¨¡æ—¶çš„æ ‡å‡†åŒ–å™¨æ–‡ä»¶
        - é¢„æµ‹æ—¶å°†ä½¿ç”¨å½“å‰æ•°æ®é‡æ–°è®¡ç®—æ ‡å‡†åŒ–å‚æ•°
        - è¿™å¯èƒ½å¯¼è‡´ä¸å»ºæ¨¡æ—¶ä¸ä¸€è‡´ï¼Œå½±å“é¢„æµ‹å‡†ç¡®æ€§
        - è¯·ç¡®ä¿å°† `scaler.pkl` æ”¾åœ¨ `final_results/` ç›®å½•ä¸‹
        """)

    # æ˜¾ç¤ºæ¨¡å‹ä½¿ç”¨çš„ç‰¹å¾
    if selected_features:
        st.sidebar.header("ğŸ“Š æ¨¡å‹ç‰¹å¾ä¿¡æ¯")
        st.sidebar.info(f"æ¨¡å‹ä½¿ç”¨ {len(selected_features)} ä¸ªç‰¹å¾")
        with st.sidebar.expander("æŸ¥çœ‹ç‰¹å¾åˆ—è¡¨"):
            for i, feat in enumerate(selected_features, 1):
                chinese_name = REVERSE_FEATURE_MAPPING.get(feat, feat)
                st.sidebar.write(f"{i}. {chinese_name} ({feat})")

    # ä¾§è¾¹æ è®¾ç½®
    st.sidebar.header("ğŸ¥ åŒ»ç–—æœºæ„å±‚æ¬¡")
    facility_level = st.sidebar.radio(
        "é€‰æ‹©å±‚æ¬¡ï¼š",
        ["åˆçº§ï¼ˆä»…åŸºæœ¬ä¿¡æ¯ï¼‰", "é«˜çº§ï¼ˆå…¨éƒ¨æŒ‡æ ‡ï¼‰"],
        index=1
    )
    selected_groups = ['basic'] if facility_level == "åˆçº§ï¼ˆä»…åŸºæœ¬ä¿¡æ¯ï¼‰" else ['basic', 'advanced']

    st.sidebar.header("ğŸ” é¢„æµ‹æ¨¡å¼")
    prediction_mode = st.sidebar.radio(
        "é€‰æ‹©æ¨¡å¼ï¼š",
        ["å•æ‚£è€…é¢„æµ‹", "æ‰¹é‡é¢„æµ‹"],
        index=0
    )

    # æ–‡ä»¶æ ¼å¼è®¾ç½®
    file_format = "Excel (.xlsx)"
    if prediction_mode == "æ‰¹é‡é¢„æµ‹":
        st.sidebar.header("ğŸ“ æ‰¹é‡é¢„æµ‹è®¾ç½®")
        file_format = st.sidebar.radio("æ–‡ä»¶æ ¼å¼ï¼š", ["Excel (.xlsx)", "CSV (.csv)"], index=0)

        # ç”Ÿæˆæ¨¡æ¿
        st.sidebar.markdown("### ğŸ“‹ æ•°æ®æ¨¡æ¿")
        template_data = {}
        for group_key in selected_groups:
            for feat in FEATURE_GROUPS[group_key]['features']:
                if feat == 'æ€§åˆ«':
                    template_data[feat] = [1]  # é»˜è®¤ç”·æ€§
                elif feat == 'å¹´é¾„':
                    template_data[feat] = [50]
                elif feat == 'ç³–å°¿ç—…ç—…ç¨‹':
                    template_data[feat] = [5.0]
                elif feat == 'BMI':
                    template_data[feat] = [24.0]
                elif feat == 'è…°è‡€æ¯”':
                    template_data[feat] = [0.9]
                elif feat == 'é«˜è¡€å‹ç—…ç¨‹':
                    template_data[feat] = [0.0]
                elif feat in ['æ”¶ç¼©å‹', 'èˆ’å¼ å‹']:
                    template_data[feat] = [120.0 if feat == 'æ”¶ç¼©å‹' else 80.0]
                elif feat == 'è¡€å°¿ç´ æ°®':
                    template_data[feat] = [5.0]
                elif feat == 'è¡€æ¸…è‚Œé…':
                    template_data[feat] = [70.0]
                elif feat == 'å°¿é…¸':
                    template_data[feat] = [300.0]
                elif feat == 'æ€»è›‹ç™½':
                    template_data[feat] = [70.0]
                elif feat == 'ç™½è›‹ç™½':
                    template_data[feat] = [45.0]
                elif feat == 'æ€»èƒ†çº¢ç´ ':
                    template_data[feat] = [12.0]
                elif feat == 'ç›´æ¥èƒ†çº¢ç´ ':
                    template_data[feat] = [4.0]
                elif feat == 'è°·ä¸™è½¬æ°¨é…¶':
                    template_data[feat] = [25.0]
                elif feat == 'è°·è‰è½¬æ°¨é…¶':
                    template_data[feat] = [26.0]
                elif feat == 'ç©ºè…¹è¡€ç³–':
                    template_data[feat] = [6.5]
                elif feat == 'ç³–åŒ–è¡€çº¢è›‹ç™½':
                    template_data[feat] = [6.5]
                elif feat == 'å°¿ç™½è›‹ç™½æ’æ³„ç‡':
                    template_data[feat] = [20.0]
                else:
                    template_data[feat] = [0.0]
        template_df = pd.DataFrame(template_data)

        # æ¨¡æ¿ä¸‹è½½é“¾æ¥
        if file_format == "Excel (.xlsx)":
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                template_df.to_excel(writer, index=False, sheet_name='æ¨¡æ¿')
            excel_data = output.getvalue()
            b64 = base64.b64encode(excel_data).decode()
            href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="pdré¢„æµ‹æ¨¡æ¿.xlsx">ğŸ“¥ ä¸‹è½½Excelæ¨¡æ¿</a>'
        else:
            csv = template_df.to_csv(index=False, encoding='utf-8-sig')
            b64 = base64.b64encode(csv.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="pdré¢„æµ‹æ¨¡æ¿.csv">ğŸ“¥ ä¸‹è½½CSVæ¨¡æ¿</a>'
        st.sidebar.markdown(href, unsafe_allow_html=True)

        st.sidebar.markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
        st.sidebar.info("""
        **é‡è¦æç¤ºï¼š**
        1. ä¸‹è½½æ¨¡æ¿å¹¶å¡«å†™æ‚£è€…æ•°æ®
        2. **ç¡®ä¿æ€§åˆ«åˆ—ä¸ºï¼š1(ç”·) æˆ– 2(å¥³)**
        3. **æ•°å€¼åˆ—åªå¡«å†™æ•°å­—ï¼Œä¸è¦æœ‰ä¸­æ–‡æˆ–ç¬¦å·**
        4. **ç©ºå•å…ƒæ ¼æˆ–ç¼ºå¤±æ•°æ®è¯·ç•™ç©ºï¼Œä¸è¦å¡«å†™ç©ºæ ¼**
        5. ä¸Šä¼ å¡«å†™å¥½çš„æ–‡ä»¶
        6. ç‚¹å‡»"å¼€å§‹æ‰¹é‡é¢„æµ‹"
        7. æŸ¥çœ‹å¹¶ä¸‹è½½ç»“æœ

        **æ”¯æŒçš„æ€§åˆ«æ ¼å¼ï¼š**
        - æ•°å­—: 1 (ç”·), 2 (å¥³)
        - ä¸­æ–‡: ç”·, å¥³
        - è‹±æ–‡: male, female, M, F

        **æ•°æ®æ¸…æ´—è§„åˆ™ï¼š**
        - ç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…é™¤ç©ºæ ¼ã€ä¸­æ–‡é€—å·ç­‰éæ•°å­—å­—ç¬¦
        - ç©ºå­—ç¬¦ä¸²ä¼šè¢«è§†ä¸ºç¼ºå¤±å€¼
        - éæ•°å­—å­—ç¬¦ä¼šè¢«æå–æ•°å­—éƒ¨åˆ†æˆ–è½¬æ¢ä¸ºNaN
        """)

    st.sidebar.header("â„¹ï¸ å…³äº")
    st.sidebar.info("æœ¬ç³»ç»ŸåŸºäºLightGBMæ¨¡å‹ï¼Œä»…ä¾›åŒ»ç–—å‚è€ƒï¼")
    st.sidebar.header("ğŸ“Š æ¨¡å‹ä¿¡æ¯")
    st.sidebar.text(f"å±‚æ¬¡ï¼š{facility_level}")
    st.sidebar.text(f"æ¨¡å¼ï¼š{prediction_mode}")

    # å•æ‚£è€…é¢„æµ‹ç•Œé¢
    if prediction_mode == "å•æ‚£è€…é¢„æµ‹":
        col1, col2 = st.columns([2, 1])

        with col1:
            st.header("ğŸ“ æ‚£è€…ä¿¡æ¯è¾“å…¥")
            st.markdown(f"**å½“å‰å±‚æ¬¡ï¼š{facility_level}**")

            with st.form("prediction_form"):
                input_values = {}
                # æ˜¾ç¤ºè¾“å…¥å­—æ®µ
                for group_key in selected_groups:
                    group = FEATURE_GROUPS[group_key]
                    st.subheader(group['name'])
                    features = group['features']
                    # æ’ç‰ˆä¼˜åŒ–
                    if len(features) <= 5:
                        cols = st.columns(len(features))
                        for idx, feat in enumerate(features):
                            with cols[idx]:
                                input_values[feat] = create_input_field_chinese(feat)
                    else:
                        num_rows = (len(features) + 2) // 3
                        for row in range(num_rows):
                            row_feats = features[row * 3:(row + 1) * 3]
                            if row_feats:
                                cols = st.columns(3)
                                for idx, feat in enumerate(row_feats):
                                    with cols[idx]:
                                        input_values[feat] = create_input_field_chinese(feat)
                # æäº¤æŒ‰é’®
                submitted = st.form_submit_button("ğŸ” å¼€å§‹é¢„æµ‹", use_container_width=True)

        with col2:
            st.header("ğŸ“Š é¢„æµ‹ç»“æœ")
            if submitted:
                with st.spinner("åˆ†ææ•°æ®ä¸­..."):
                    prob, pred = predict_single_patient(input_values, model, feature_info)
                    if prob is not None:
                        # å¯è§†åŒ–é£é™©æ¦‚ç‡ï¼ˆå•æ‚£è€…é¢„æµ‹ä¿ç•™ï¼‰
                        fig, ax = plt.subplots(figsize=(8, 4))
                        risk_level = "é«˜é£é™©" if pred == 1 else "ä½é£é™©"
                        color = '#FF4B4B' if pred == 1 else '#00D4AA'
                        ax.barh([0], [prob * 100], color=color, alpha=0.7)
                        ax.set_xlim(0, 100)
                        ax.set_xlabel('PDRé£é™©æ¦‚ç‡ (%)')
                        ax.set_yticks([])
                        ax.set_title(f'é£é™©æ¦‚ç‡: {prob * 100:.2f}%')
                        ax.axvline(x=50, color='red', linestyle='--', alpha=0.5, label='é˜ˆå€¼')
                        ax.legend()
                        st.pyplot(fig)

                        # ç»“æœå±•ç¤º
                        st.metric("é¢„æµ‹ç»“æœ", risk_level, delta=f"{prob * 100:.2f}%")

                        # ä½¿ç”¨çš„ç‰¹å¾
                        with st.expander("ğŸ“‹ ä½¿ç”¨çš„ç‰¹å¾"):
                            used_feats = []
                            for g in selected_groups:
                                used_feats.extend(FEATURE_GROUPS[g]['features'])
                            st.write(f"æ€»æ•°: {len(used_feats)}")
                            for i, feat in enumerate(used_feats, 1):
                                st.write(f"{i}. {feat}")

                        # å»ºè®®
                        st.subheader("ğŸ’¡ å»ºè®®")
                        if pred == 1:
                            st.error("""
                            âš ï¸ **é«˜é£é™©é¢„è­¦**:
                            â€¢ ç«‹å³è¿›è¡Œçœ¼ç§‘è¯¦ç»†æ£€æŸ¥
                            â€¢ ä¸¥æ ¼æ§åˆ¶è¡€ç³–/è¡€å‹
                            â€¢ å®šæœŸçœ¼åº•æ£€æŸ¥
                            â€¢ éµåŒ»å˜±å¹²é¢„
                            """)
                        else:
                            st.success("""
                            âœ… **ä½é£é™©æç¤º**:
                            â€¢ ä¿æŒè¡€ç³–æ§åˆ¶
                            â€¢ æ¯å¹´ä¸€æ¬¡çœ¼ç§‘æ£€æŸ¥
                            â€¢ å¥åº·ç”Ÿæ´»æ–¹å¼
                            â€¢ è§†åŠ›å˜åŒ–åŠæ—¶å°±åŒ»
                            """)
                        st.info("âš ï¸ å…è´£å£°æ˜ï¼šç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ›¿ä»£ä¸“ä¸šè¯Šæ–­ï¼")
            else:
                st.info("è¯·å¡«å†™å·¦ä¾§ä¿¡æ¯å¹¶ç‚¹å‡»é¢„æµ‹æŒ‰é’®")
                with st.expander("ğŸ“‹ å¯ç”¨ç‰¹å¾"):
                    used_feats = []
                    for g in selected_groups:
                        group = FEATURE_GROUPS[g]
                        st.write(f"**{group['name']}** ({len(group['features'])}ä¸ª):")
                        for i, feat in enumerate(group['features'], 1):
                            st.write(f"  {i}. {feat}")
                        used_feats.extend(group['features'])
                    st.write(f"\n**æ€»ç‰¹å¾æ•°: {len(used_feats)}**")

    # æ‰¹é‡é¢„æµ‹ç•Œé¢
    else:
        st.header("ğŸ“ æ‰¹é‡é¢„æµ‹")
        st.markdown(f"**å½“å‰çº§åˆ«: {facility_level}**")

        # æ–‡ä»¶ä¸Šä¼ 
        if file_format == "Excel (.xlsx)":
            uploaded_file = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=['xlsx', 'xls'],
                                             help="ä½¿ç”¨å·¦ä¾§æ¨¡æ¿ï¼Œæ”¯æŒä¸­æ–‡åˆ—åï¼")
        else:
            uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type=['csv'],
                                             help="ä½¿ç”¨å·¦ä¾§æ¨¡æ¿ï¼Œæ”¯æŒä¸­æ–‡åˆ—åï¼")

        if uploaded_file is not None:
            try:
                # è¯»å–æ–‡ä»¶
                if uploaded_file.name.endswith(('.xlsx', '.xls')):
                    batch_df = pd.read_excel(uploaded_file, engine='openpyxl')
                else:
                    batch_df = pd.read_csv(uploaded_file)
                st.success(f"âœ… æˆåŠŸè¯»å– {len(batch_df)} è¡Œæ•°æ®ï¼")

                # æ•°æ®é¢„è§ˆ
                st.subheader("ğŸ“‹ æ•°æ®é¢„è§ˆ")
                st.write(f"æ•°æ®å½¢çŠ¶: {batch_df.shape}")
                st.write(f"åˆ—å: {list(batch_df.columns)}")
                st.dataframe(batch_df.head(), use_container_width=True)

                # æ•°æ®ç»Ÿè®¡
                with st.expander("ğŸ“Š æ•°æ®ç»Ÿè®¡"):
                    st.write("**æ•°å€¼ç‰¹å¾ç»Ÿè®¡:**")
                    numeric_cols = batch_df.select_dtypes(include=[np.number]).columns
                    if numeric_cols.empty:
                        st.write("æ— æ•°å€¼å‹ç‰¹å¾")
                    else:
                        st.dataframe(batch_df[numeric_cols].describe())

                    st.write("**ç¼ºå¤±å€¼ç»Ÿè®¡:**")
                    missing = batch_df.isnull().sum()
                    missing_df = pd.DataFrame({
                        'ç‰¹å¾': missing.index,
                        'ç¼ºå¤±æ•°': missing.values,
                        'ç¼ºå¤±ç‡(%)': (missing / len(batch_df) * 100).round(2)
                    })
                    missing_df = missing_df[missing_df['ç¼ºå¤±æ•°'] > 0]
                    if missing_df.empty:
                        st.success("âœ… æ— ç¼ºå¤±å€¼ï¼")
                    else:
                        st.dataframe(missing_df)

                    st.write("**æ•°æ®ç±»å‹ç»Ÿè®¡:**")
                    dtypes_df = pd.DataFrame({
                        'ç‰¹å¾': batch_df.columns,
                        'æ•°æ®ç±»å‹': batch_df.dtypes.values
                    })
                    st.dataframe(dtypes_df)

                # æ‰¹é‡é¢„æµ‹æŒ‰é’®
                if st.button("ğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹", type="primary", use_container_width=True):
                    with st.spinner(f"é¢„æµ‹ä¸­ï¼ˆå…±{len(batch_df)}æ¡æ•°æ®ï¼‰..."):
                        results_df = batch_predict(batch_df, model, feature_info, selected_features)

                    if results_df is not None:
                        # ç»“æœå±•ç¤º
                        st.subheader("ğŸ“Š é¢„æµ‹ç»“æœ")
                        # ç»Ÿè®¡ä¿¡æ¯
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("æ€»æ‚£è€…æ•°", len(results_df))
                        with col2:
                            high_risk = (results_df['PDRé¢„æµ‹æ¦‚ç‡'] > 0.95).sum()
                            st.metric("é«˜é£é™©", high_risk)
                        with col3:
                            mid_risk = ((results_df['PDRé¢„æµ‹æ¦‚ç‡'] >= 0.5) & (results_df['PDRé¢„æµ‹æ¦‚ç‡'] <= 0.95)).sum()
                            st.metric("ä¸­é£é™©", mid_risk)
                        with col4:
                            low_risk = (results_df['PDRé¢„æµ‹æ¦‚ç‡'] < 0.5).sum()
                            st.metric("ä½é£é™©", low_risk)

                        # é«˜é£é™©æ‚£è€…è¯¦æƒ…
                        high_risk_df = results_df[results_df['PDRé£é™©ç­‰çº§'] == 'é«˜é£é™©']
                        if not high_risk_df.empty:
                            st.warning(f"âš ï¸ å‘ç° {len(high_risk_df)} åé«˜é£é™©æ‚£è€…ï¼")
                            with st.expander("ğŸ”´ é«˜é£é™©æ‚£è€…è¯¦æƒ…"):
                                st.dataframe(high_risk_df, use_container_width=True)

                        # ç»“æœç­›é€‰
                        st.subheader("ğŸ“‹ è¯¦ç»†ç»“æœ")
                        filter_col1, filter_col2 = st.columns(2)
                        with filter_col1:
                            risk_filter = st.selectbox("æŒ‰é£é™©ç­›é€‰:", ["å…¨éƒ¨", "é«˜é£é™©", "ä¸­é£é™©", "ä½é£é™©"])
                        with filter_col2:
                            prob_filter = st.slider("æŒ‰æ¦‚ç‡ç­›é€‰:", 0.0, 1.0, (0.0, 1.0), 0.01)

                        # åº”ç”¨ç­›é€‰
                        filtered_df = results_df.copy()
                        if risk_filter != "å…¨éƒ¨":
                            filtered_df = filtered_df[filtered_df['PDRé£é™©ç­‰çº§'] == risk_filter]
                        filtered_df = filtered_df[
                            (filtered_df['PDRé¢„æµ‹æ¦‚ç‡'] >= prob_filter[0]) &
                            (filtered_df['PDRé¢„æµ‹æ¦‚ç‡'] <= prob_filter[1])
                            ]
                        st.write(f"ç­›é€‰ç»“æœ: {len(filtered_df)} æ¡")
                        st.dataframe(filtered_df, use_container_width=True)

                        # ä¸‹è½½ç»“æœ
                        st.markdown("### ğŸ’¾ ä¸‹è½½ç»“æœ")
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        col1, col2 = st.columns(2)
                        with col1:
                            excel_name = f"pdré¢„æµ‹ç»“æœ_{timestamp}.xlsx"
                            st.markdown(get_table_download_link(results_df, excel_name, "excel"),
                                        unsafe_allow_html=True)
                        with col2:
                            csv_name = f"pdré¢„æµ‹ç»“æœ_{timestamp}.csv"
                            st.markdown(get_table_download_link(results_df, csv_name, "csv"),
                                        unsafe_allow_html=True)

                        # é«˜é£é™©æ‚£è€…å•ç‹¬ä¸‹è½½
                        if not high_risk_df.empty:
                            st.markdown("#### ğŸ”´ é«˜é£é™©æ‚£è€…ä¸‹è½½")
                            high_name = f"pdré«˜é£é™©æ‚£è€…_{timestamp}.xlsx"
                            st.markdown(get_table_download_link(high_risk_df, high_name, "excel"),
                                        unsafe_allow_html=True)

            except Exception as e:
                st.error(f"å¤„ç†æ–‡ä»¶å‡ºé”™: {str(e)}")
                import traceback
                st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                st.info("""
                **â— å¸¸è§é—®é¢˜è§£å†³ï¼š**
                1. **æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦æœ‰éæ•°å­—å­—ç¬¦ï¼ˆå¦‚ç©ºæ ¼ã€ä¸­æ–‡ã€ç‰¹æ®Šç¬¦å·ï¼‰**
                2. **ç¡®ä¿æ€§åˆ«åˆ—ä»…å¡«å†™1/2ï¼Œæˆ–ä½¿ç”¨ä¸­æ–‡"ç”·"/"å¥³"**
                3. **æ•°å€¼åˆ—åªå¡«å†™æ•°å­—ï¼Œä¸è¦æœ‰å•ä½æˆ–ç¬¦å·**
                4. **ä¸‹è½½å·¦ä¾§æ¨¡æ¿ï¼ŒæŒ‰æ¨¡æ¿æ ¼å¼å¡«å†™æ•°æ®**
                5. ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç‰¹å¾åˆ—
                6. **ç©ºå•å…ƒæ ¼è¯·ç•™ç©ºï¼Œä¸è¦å¡«å†™ç©ºæ ¼æˆ–ä»»ä½•å­—ç¬¦**
                """)
        else:
            # æ‰¹é‡é¢„æµ‹è¯´æ˜
            st.info(f"""
            ## ğŸ“ æ‰¹é‡é¢„æµ‹è¯´æ˜ï¼ˆ{file_format}ï¼‰
            1. ä¸‹è½½å·¦ä¾§æ¨¡æ¿å¹¶å¡«å†™æ•°æ®
            2. ä¸Šä¼ å¡«å†™å¥½çš„{file_format}æ–‡ä»¶
            3. ç‚¹å‡»"å¼€å§‹æ‰¹é‡é¢„æµ‹"
            4. æŸ¥çœ‹ç»Ÿè®¡ç»“æœå¹¶ä¸‹è½½

            ### ğŸ“‹ æ•°æ®è¦æ±‚
            - åˆ—åä¸æ¨¡æ¿ä¸€è‡´ï¼ˆä¸­æ–‡ï¼‰
            - **æ€§åˆ«åˆ—å¡«ï¼š1(ç”·) æˆ– 2(å¥³)**ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            - **æ•°å€¼ç‰¹å¾å¡«æ•°å­—ï¼Œä¸è¦æœ‰å•ä½æˆ–ç¬¦å·**
            - **ç©ºç™½å•å…ƒæ ¼æˆ–ç¼ºå¤±æ•°æ®è¯·ç•™ç©ºï¼Œä¸è¦å¡«å†™ç©ºæ ¼**
            - ç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…æ´—æ•°æ®å¹¶å¤„ç†ç¼ºå¤±å€¼
            """)

    # åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: gray;'>åŸºäºLightGBMæ¨¡å‹ | ä»…ä¾›åŒ»ç–—ä¸“ä¸šäººå‘˜å‚è€ƒ</div>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()