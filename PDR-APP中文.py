import streamlit as st
import pandas as pd
import numpy as np
import joblib
import pickle
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import sys
import io
import base64
from datetime import datetime
import seaborn as sns

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="PDRé£é™©é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ‘ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
st.sidebar.header("ç¯å¢ƒä¿¡æ¯")
st.sidebar.text(f"Python: {sys.version.split()[0]}")

# === æ ¸å¿ƒä¿®æ”¹1ï¼šå®šä¹‰ä¸¤çº§ç‰¹å¾ç»„ (åŸä¸ºä¸‰çº§) ===
FEATURE_GROUPS = {
    'basic': {
        'name': 'åŸºæœ¬ä¿¡æ¯',
        'features': ['æ€§åˆ«', 'å¹´é¾„', 'ç³–å°¿ç—…ç—…ç¨‹', 'BMI', 'è…°è‡€æ¯”','æ”¶ç¼©å‹', 'èˆ’å¼ å‹',
                     'é«˜è¡€å‹ç—…ç¨‹']
    },
    'advanced': {
        'name': 'è¡€å‹å’Œå®éªŒå®¤æŒ‡æ ‡',
        'features': ['è¡€å°¿ç´ æ°®', 'è¡€æ¸…è‚Œé…', 'å°¿é…¸', 'æ€»è›‹ç™½', 'ç™½è›‹ç™½', 'æ€»èƒ†çº¢ç´ ', 'ç›´æ¥èƒ†çº¢ç´ ', 'è°·ä¸™è½¬æ°¨é…¶', 'è°·è‰è½¬æ°¨é…¶', 'ç©ºè…¹è¡€ç³–', 'ç³–åŒ–è¡€çº¢è›‹ç™½', 'å°¿ç™½è›‹ç™½æ’æ³„ç‡']
    }
}
# === æ ¸å¿ƒä¿®æ”¹1ç»“æŸ ===

# åˆ›å»ºä¸‹è½½é“¾æ¥çš„å‡½æ•°
def get_table_download_link(df, filename="é¢„æµ‹ç»“æœ.xlsx", format="excel"):
    """ç”ŸæˆExcelæˆ–CSVä¸‹è½½é“¾æ¥"""
    if format == "excel":
        # ç”ŸæˆExcelæ–‡ä»¶
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='é¢„æµ‹ç»“æœ')
        excel_data = output.getvalue()
        b64 = base64.b64encode(excel_data).decode()
        href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ (Excel)</a>'
    else:
        # ç”ŸæˆCSVæ–‡ä»¶
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename.replace(".xlsx", ".csv")}">ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ (CSV)</a>'
    return href

# åŠ è½½æ¨¡å‹å’Œé¢„å¤„ç†å·¥å…·
@st.cache_resource
def load_model_and_preprocessors():
    try:
        model = joblib.load('final_results/lightgbm_pdr_model.pkl')
        scaler = joblib.load('final_results/scaler.pkl')
        median_imputer = joblib.load('final_results/median_imputer.pkl')
        mode_imputer = joblib.load('final_results/mode_imputer.pkl')

        with open('final_results/feature_info.pkl', 'rb') as f:
            feature_info = pickle.load(f)

        # åŠ è½½é€‰æ‹©çš„ç‰¹å¾
        selected_features = pd.read_csv('final_results/selected_features.csv').iloc[:, 0].tolist()

        return model, scaler, median_imputer, mode_imputer, feature_info, selected_features
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return None, None, None, None, None, None

# é¢„å¤„ç†æ‰¹é‡æ•°æ®
def preprocess_batch_data(batch_df, feature_info, median_imputer, mode_imputer, scaler, selected_features):
    """æ‰¹é‡é¢„å¤„ç†æ•°æ®"""

    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
    required_columns = feature_info['feature_names']
    missing_cols = set(required_columns) - set(batch_df.columns)

    if missing_cols:
        st.warning(f"âš ï¸ æ•°æ®ä¸­ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{list(missing_cols)}")
        # ä¸ºç¼ºå¤±çš„åˆ—å¡«å……NaN
        for col in missing_cols:
            batch_df[col] = np.nan

    # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
    batch_df = batch_df[required_columns]

    # å¤åˆ¶ä¸€ä»½åŸå§‹æ•°æ®ç”¨äºç»“æœè¾“å‡º
    original_df = batch_df.copy()

    # åˆ†åˆ«å¤„ç†æ•°å€¼å‹å’Œåˆ†ç±»å‹ç‰¹å¾
    numeric_data = batch_df[feature_info['numeric_features']].copy()
    categorical_data = batch_df[feature_info['categorical_features']].copy()

    # å¤„ç†ç¼ºå¤±å€¼
    if numeric_data.isnull().any().any():
        missing_count = numeric_data.isnull().sum().sum()
        st.info(f"ğŸ” æ•°å€¼å‹ç‰¹å¾ç¼ºå¤±å€¼æ•°é‡ï¼š{missing_count}")
        numeric_data = pd.DataFrame(
            median_imputer.transform(numeric_data),
            columns=feature_info['numeric_features']
        )

    if categorical_data.isnull().any().any():
        missing_count = categorical_data.isnull().sum().sum()
        st.info(f"ğŸ” åˆ†ç±»å‹ç‰¹å¾ç¼ºå¤±å€¼æ•°é‡ï¼š{missing_count}")
        categorical_data = pd.DataFrame(
            mode_imputer.transform(categorical_data),
            columns=feature_info['categorical_features']
        )

    # åˆå¹¶æ•°æ®
    processed_data = pd.concat([numeric_data, categorical_data], axis=1)

    # æ ‡å‡†åŒ–æ•°å€¼å‹ç‰¹å¾
    numeric_features_standardized = pd.DataFrame(
        scaler.transform(processed_data[feature_info['numeric_features']]),
        columns=feature_info['numeric_features']
    )

    # æ›´æ–°æ•°å€¼å‹ç‰¹å¾
    processed_data[feature_info['numeric_features']] = numeric_features_standardized

    # åªä¿ç•™é€‰æ‹©çš„ç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶ç›¸åŒï¼‰
    processed_data_selected = processed_data[selected_features]

    return processed_data_selected, original_df

# æ‰¹é‡é¢„æµ‹å‡½æ•°
def batch_predict(batch_df, model, feature_info, median_imputer, mode_imputer, scaler, selected_features):
    """æ‰¹é‡é¢„æµ‹"""

    # é¢„å¤„ç†æ•°æ®
    processed_data, original_df = preprocess_batch_data(
        batch_df, feature_info, median_imputer, mode_imputer, scaler, selected_features
    )

    # è¿›è¡Œé¢„æµ‹
    probabilities = model.predict_proba(processed_data)[:, 1]
    predictions = model.predict(processed_data)

    # ç¡®å®šé£é™©ç­‰çº§
    def get_risk_level(prob):
        if prob < 0.3:
            return "ä½é£é™©"
        elif prob < 0.7:
            return "ä¸­é£é™©"
        else:
            return "é«˜é£é™©"

    risk_levels = [get_risk_level(prob) for prob in probabilities]

    # åˆ›å»ºç»“æœDataFrame
    results_df = original_df.copy()
    results_df['PDRé¢„æµ‹æ¦‚ç‡'] = probabilities
    results_df['PDRé¢„æµ‹ç±»åˆ«'] = predictions
    results_df['PDRé£é™©ç­‰çº§'] = risk_levels
    results_df['é¢„æµ‹æ—¶é—´'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    return results_df

# åˆ›å»ºè¾“å…¥å­—æ®µå‡½æ•°ï¼ˆå•ä¸ªæ‚£è€…ç”¨ï¼‰
def create_input_field(feature_name, feature_type, feature_info):
    """æ ¹æ®ç‰¹å¾ç±»å‹åˆ›å»ºä¸åŒçš„è¾“å…¥å­—æ®µ"""

    if feature_type == 'numeric':
        # æ•°å€¼å‹ç‰¹å¾
        if feature_name == 'æ€§åˆ«':
            options = [("å¥³æ€§", 0), ("ç”·æ€§", 1)]
            selected = st.selectbox("æ€§åˆ«", options=options, format_func=lambda x: x[0])
            return selected[1]
        elif feature_name == 'å¸çƒŸå²':
            options = [("å¦", 0), ("æ˜¯", 1)]
            selected = st.selectbox("å¸çƒŸå²", options=options, format_func=lambda x: x[0])
            return selected[1]
        elif feature_name == 'é¥®é…’å²':
            options = [("å¦", 0), ("æ˜¯", 1)]
            selected = st.selectbox("é¥®é…’å²", options=options, format_func=lambda x: x[0])
            return selected[1]
        elif feature_name == 'é«˜è¡€å‹ç—…å²':
            options = [("å¦", 0), ("æ˜¯", 1)]
            selected = st.selectbox("é«˜è¡€å‹ç—…å²", options=options, format_func=lambda x: x[0])
            return selected[1]
        elif feature_name == 'å¹´é¾„':
            return st.number_input("å¹´é¾„ï¼ˆå²ï¼‰", min_value=0, max_value=120, value=50, step=1)
        elif feature_name == 'ç³–å°¿ç—…ç—…ç¨‹':
            return st.number_input("ç³–å°¿ç—…ç—…ç¨‹ï¼ˆå¹´ï¼‰", min_value=0.0, max_value=50.0, value=5.0, step=0.5)
        elif feature_name == 'BMI':
            return st.number_input("BMIï¼ˆä½“é‡æŒ‡æ•°ï¼‰", min_value=10.0, max_value=50.0, value=24.0, step=0.1)
        elif feature_name == 'è…°è‡€æ¯”':
            return st.number_input("è…°è‡€æ¯”ï¼ˆWHRï¼‰", min_value=0.5, max_value=1.5, value=0.9, step=0.01)
        elif feature_name == 'é«˜è¡€å‹ç—…ç¨‹':
            return st.number_input("é«˜è¡€å‹ç—…ç¨‹ï¼ˆå¹´ï¼‰", min_value=0.0, max_value=50.0, value=0.0, step=0.5)
        elif feature_name == 'æ”¶ç¼©å‹':
            return st.number_input("æ”¶ç¼©å‹ï¼ˆmmHgï¼‰", min_value=60.0, max_value=250.0, value=120.0,
                                   step=1.0)
        elif feature_name == 'èˆ’å¼ å‹':
            return st.number_input("èˆ’å¼ å‹ï¼ˆmmHgï¼‰", min_value=40.0, max_value=150.0, value=80.0,
                                   step=1.0)
        elif feature_name == 'è¡€å°¿ç´ æ°®':
            return st.number_input("è¡€å°¿ç´ æ°®ï¼ˆBUN, mmol/Lï¼‰", min_value=1.0, max_value=30.0, value=5.0,
                                   step=0.1)
        elif feature_name == 'è¡€æ¸…è‚Œé…':
            return st.number_input("è¡€æ¸…è‚Œé…ï¼ˆScr, Î¼mol/Lï¼‰", min_value=20.0, max_value=500.0, value=70.0,
                                   step=1.0)
        elif feature_name == 'å°¿é…¸':
            return st.number_input("å°¿é…¸ï¼ˆUA, Î¼mol/Lï¼‰", min_value=100.0, max_value=800.0, value=300.0, step=1.0)
        elif feature_name == 'æ€»è›‹ç™½':
            return st.number_input("æ€»è›‹ç™½ï¼ˆTP, g/Lï¼‰", min_value=40.0, max_value=100.0, value=70.0, step=0.1)
        elif feature_name == 'ç™½è›‹ç™½':
            return st.number_input("ç™½è›‹ç™½ï¼ˆALB, g/Lï¼‰", min_value=20.0, max_value=60.0, value=45.0, step=0.1)
        elif feature_name == 'æ€»èƒ†çº¢ç´ ':
            return st.number_input("æ€»èƒ†çº¢ç´ ï¼ˆTBIL, Î¼mol/Lï¼‰", min_value=1.0, max_value=100.0, value=12.0,
                                   step=0.1)
        elif feature_name == 'ç›´æ¥èƒ†çº¢ç´ ':
            return st.number_input("ç›´æ¥èƒ†çº¢ç´ ï¼ˆDBIL, Î¼mol/Lï¼‰", min_value=0.0, max_value=50.0, value=4.0,
                                   step=0.1)
        elif feature_name == 'è°·ä¸™è½¬æ°¨é…¶':
            return st.number_input("è°·ä¸™è½¬æ°¨é…¶ï¼ˆALT, U/Lï¼‰", min_value=5.0, max_value=200.0, value=25.0, step=1.0)
        elif feature_name == 'è°·è‰è½¬æ°¨é…¶':
            return st.number_input("è°·è‰è½¬æ°¨é…¶ï¼ˆAST, U/Lï¼‰", min_value=5.0, max_value=200.0, value=26.0, step=1.0)
        elif feature_name == 'ç©ºè…¹è¡€ç³–':
            return st.number_input("ç©ºè…¹è¡€ç³–ï¼ˆFBG, mmol/Lï¼‰", min_value=3.0, max_value=30.0, value=6.5,
                                   step=0.1)
        elif feature_name == 'ç³–åŒ–è¡€çº¢è›‹ç™½':
            return st.number_input("ç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1c, %ï¼‰", min_value=4.0, max_value=15.0, value=6.5, step=0.1)
        elif feature_name == 'å°¿ç™½è›‹ç™½æ’æ³„ç‡':
            return st.number_input("å°¿ç™½è›‹ç™½æ’æ³„ç‡ï¼ˆUAER, Î¼g/minï¼‰", min_value=0.0, max_value=500.0,
                                   value=20.0, step=1.0)
        else:
            return st.number_input(f"{feature_name}", min_value=0, max_value=100, value=50, step=1.0)

    return 0

# å•ä¸ªæ‚£è€…é¢„æµ‹å‡½æ•°
def predict_single_patient(input_data, model, scaler, median_imputer, mode_imputer, feature_info):
    try:
        # è½¬æ¢ä¸ºDataFrame
        input_df = pd.DataFrame([input_data], columns=feature_info['feature_names'])

        # æ•°æ®é¢„å¤„ç†
        numeric_data = median_imputer.transform(input_df[feature_info['numeric_features']])
        categorical_data = mode_imputer.transform(input_df[feature_info['categorical_features']])

        # é‡æ–°ç»„åˆ
        processed_data = np.column_stack([numeric_data, categorical_data])
        processed_df = pd.DataFrame(processed_data, columns=feature_info['feature_names'])

        # æ ‡å‡†åŒ–
        scaled_data = scaler.transform(processed_df)

        # é¢„æµ‹
        probability = model.predict_proba(scaled_data)[0][1]
        prediction = model.predict(scaled_data)[0]

        return probability, prediction

    except Exception as e:
        st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return None, None

# ä¸»åº”ç”¨
def main():
    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ‘ï¸ ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ï¼ˆPDRï¼‰é£é™©é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")

    # åŠ è½½æ¨¡å‹
    with st.spinner("æ­£åœ¨åŠ è½½é¢„æµ‹æ¨¡å‹..."):
        model, scaler, median_imputer, mode_imputer, feature_info, selected_features = load_model_and_preprocessors()

    if model is None:
        st.error("æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚")
        return

    # === æ ¸å¿ƒä¿®æ”¹2ï¼šä¾§è¾¹æ  - æ›´æ–°ä¸ºä¸¤çº§åŒ»ç–—æœºæ„å±‚æ¬¡é€‰æ‹© ===
    st.sidebar.header("ğŸ¥ åŒ»ç–—æœºæ„å±‚æ¬¡")
    facility_level = st.sidebar.radio(
        "é€‰æ‹©æ‚¨çš„åŒ»ç–—æœºæ„å±‚æ¬¡ï¼š",
        ["åˆçº§ï¼ˆä»…åŸºæœ¬ä¿¡æ¯ï¼‰",  # å¯¹åº” basic ç»„
         "é«˜çº§ï¼ˆå…¨éƒ¨æŒ‡æ ‡ï¼‰"],  # å¯¹åº” basic + advanced ç»„
        index=1  # é»˜è®¤é€‰ä¸­â€œé«˜çº§â€
    )

    # === æ ¸å¿ƒä¿®æ”¹3ï¼šæ›´æ–°å±‚çº§é€‰æ‹©é€»è¾‘ ===
    if facility_level == "åˆçº§ï¼ˆä»…åŸºæœ¬ä¿¡æ¯ï¼‰":
        selected_groups = ['basic']
    else:  # "é«˜çº§ï¼ˆå…¨éƒ¨æŒ‡æ ‡ï¼‰"
        selected_groups = ['basic', 'advanced']
    # === æ ¸å¿ƒä¿®æ”¹3ç»“æŸ ===

    # ä¾§è¾¹æ  - é¢„æµ‹æ¨¡å¼é€‰æ‹©
    st.sidebar.header("ğŸ” é¢„æµ‹æ¨¡å¼")
    prediction_mode = st.sidebar.radio(
        "é€‰æ‹©é¢„æµ‹æ¨¡å¼ï¼š",
        ["å•æ‚£è€…é¢„æµ‹", "æ‰¹é‡é¢„æµ‹"],
        index=0
    )

    # æ‰¹é‡é¢„æµ‹æ—¶æ˜¾ç¤ºæ–‡ä»¶ä¸Šä¼ å’Œæ¨¡æ¿ä¸‹è½½
    if prediction_mode == "æ‰¹é‡é¢„æµ‹":
        st.sidebar.header("ğŸ“ æ‰¹é‡é¢„æµ‹è®¾ç½®")

        # æ–‡ä»¶æ ¼å¼é€‰æ‹©
        file_format = st.sidebar.radio(
            "é€‰æ‹©æ–‡ä»¶æ ¼å¼ï¼š",
            ["Excel (.xlsx)", "CSV (.csv)"],
            index=0
        )

        # æä¾›æ¨¡æ¿æ–‡ä»¶ä¸‹è½½
        st.sidebar.markdown("### ğŸ“‹ æ•°æ®æ¨¡æ¿")

        # === æ ¸å¿ƒä¿®æ”¹4ï¼šæ›´æ–°æ‰¹é‡é¢„æµ‹æ¨¡æ¿ç”Ÿæˆé€»è¾‘ ===
        # åˆ›å»ºæ¨¡æ¿æ•°æ®ï¼ˆä»…åŒ…å«å½“å‰é€‰ä¸­çº§åˆ«çš„ç‰¹å¾ï¼‰
        template_data = {}
        for group_key in selected_groups:  # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„å±‚çº§åŠ¨æ€ç”Ÿæˆ
            for feature in FEATURE_GROUPS[group_key]['features']:
                # è®¾ç½®é»˜è®¤å€¼ (æ­¤éƒ¨åˆ†é€»è¾‘ä¸ä¹‹å‰ä¸€è‡´ï¼Œä½†éå†çš„ç»„ç”±selected_groupså†³å®š)
                if feature == 'æ€§åˆ«':
                    template_data[feature] = [1]
                elif feature in ['å¸çƒŸå²', 'é¥®é…’å²', 'é«˜è¡€å‹ç—…å²']:
                    template_data[feature] = [0]
                elif feature == 'å¹´é¾„':
                    template_data[feature] = [50]
                elif feature == 'ç³–å°¿ç—…ç—…ç¨‹':
                    template_data[feature] = [5.0]
                elif feature == 'BMI':
                    template_data[feature] = [24.0]
                elif feature == 'è…°è‡€æ¯”':
                    template_data[feature] = [0.9]
                elif feature == 'é«˜è¡€å‹ç—…ç¨‹':
                    template_data[feature] = [0.0]
                elif feature in ['æ”¶ç¼©å‹', 'èˆ’å¼ å‹']:
                    template_data[feature] = [120.0, 80.0][['æ”¶ç¼©å‹', 'èˆ’å¼ å‹'].index(feature)]
                elif feature == 'è¡€å°¿ç´ æ°®':
                    template_data[feature] = [5.0]
                elif feature == 'è¡€æ¸…è‚Œé…':
                    template_data[feature] = [70.0]
                elif feature == 'å°¿é…¸':
                    template_data[feature] = [300.0]
                elif feature == 'æ€»è›‹ç™½':
                    template_data[feature] = [70.0]
                elif feature == 'ç™½è›‹ç™½':
                    template_data[feature] = [45.0]
                elif feature == 'æ€»èƒ†çº¢ç´ ':
                    template_data[feature] = [12.0]
                elif feature == 'ç›´æ¥èƒ†çº¢ç´ ':
                    template_data[feature] = [4.0]
                elif feature == 'è°·ä¸™è½¬æ°¨é…¶':
                    template_data[feature] = [25.0]
                elif feature == 'è°·è‰è½¬æ°¨é…¶':
                    template_data[feature] = [26.0]
                elif feature == 'ç©ºè…¹è¡€ç³–':
                    template_data[feature] = [6.5]
                elif feature == 'ç³–åŒ–è¡€çº¢è›‹ç™½':
                    template_data[feature] = [6.5]
                elif feature == 'å°¿ç™½è›‹ç™½æ’æ³„ç‡':
                    template_data[feature] = [20.0]
                else:
                    template_data[feature] = [0.0]
        # === æ ¸å¿ƒä¿®æ”¹4ç»“æŸ ===

        template_df = pd.DataFrame(template_data)

        # æ ¹æ®é€‰æ‹©çš„æ–‡ä»¶æ ¼å¼æä¾›ä¸åŒçš„æ¨¡æ¿ä¸‹è½½
        if file_format == "Excel (.xlsx)":
            # ç”ŸæˆExcelæ¨¡æ¿
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                template_df.to_excel(writer, index=False, sheet_name='æ¨¡æ¿')
            excel_data = output.getvalue()
            b64 = base64.b64encode(excel_data).decode()
            href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="pdré¢„æµ‹æ¨¡æ¿.xlsx">ğŸ“¥ ä¸‹è½½Excelæ¨¡æ¿</a>'
        else:
            # ç”ŸæˆCSVæ¨¡æ¿
            csv = template_df.to_csv(index=False, encoding='utf-8-sig')
            b64 = base64.b64encode(csv.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="pdré¢„æµ‹æ¨¡æ¿.csv">ğŸ“¥ ä¸‹è½½CSVæ¨¡æ¿</a>'

        st.sidebar.markdown(href, unsafe_allow_html=True)

        st.sidebar.markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
        st.sidebar.info("""
        1. ä¸‹è½½ä¸Šæ–¹æ¨¡æ¿
        2. åœ¨æ¨¡æ¿ä¸­å¡«å†™æ‚£è€…æ•°æ®
        3. ä¸Šä¼ å¡«å†™å¥½çš„æ–‡ä»¶
        4. ç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œæ‰¹é‡é¢„æµ‹
        5. ä¸‹è½½åŒ…å«é¢„æµ‹ç»“æœçš„æ–‡ä»¶
        """)

    st.sidebar.header("â„¹ï¸ å…³äº")
    st.sidebar.info(
        "æœ¬ç³»ç»ŸåŸºäºLightGBMæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹å¢æ®–æ€§ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ï¼ˆPDRï¼‰çš„é£é™©ã€‚"
        "è¯·è¾“å…¥æ‚£è€…ä¸´åºŠæŒ‡æ ‡ä»¥è·å–é£é™©è¯„ä¼°ã€‚"
    )

    # === æ ¸å¿ƒä¿®æ”¹5ï¼šæ›´æ–°ä¾§è¾¹æ æ˜¾ç¤ºçš„æ¨¡å‹ä¿¡æ¯æ–‡æœ¬ ===
    st.sidebar.header("ğŸ“Š æ¨¡å‹ä¿¡æ¯")
    st.sidebar.text(f"åŒ»ç–—æœºæ„å±‚æ¬¡ï¼š{facility_level}")
    st.sidebar.text(f"é¢„æµ‹æ¨¡å¼ï¼š{prediction_mode}")
    # === æ ¸å¿ƒä¿®æ”¹5ç»“æŸ ===

    # æ ¹æ®é¢„æµ‹æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„ç•Œé¢
    if prediction_mode == "å•æ‚£è€…é¢„æµ‹":
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns([2, 1])

        with col1:
            st.header("ğŸ“ æ‚£è€…ä¿¡æ¯è¾“å…¥")
            st.markdown(f"**å½“å‰å±‚æ¬¡ï¼š{facility_level}**")

            # åˆ›å»ºè¡¨å•
            with st.form("prediction_form"):
                input_values = {}

                # æ ¹æ®é€‰æ‹©çš„ç»„æ˜¾ç¤ºç›¸åº”çš„è¾“å…¥å­—æ®µ
                for group_key in selected_groups:
                    group = FEATURE_GROUPS[group_key]
                    st.subheader(group['name'])

                    # æ ¹æ®ç‰¹å¾æ•°é‡å†³å®šåˆ—æ•°
                    features = group['features']
                    if len(features) <= 5:
                        cols = st.columns(len(features))
                        for idx, feature in enumerate(features):
                            with cols[idx]:
                                # ç¡®å®šç‰¹å¾ç±»å‹
                                if feature in feature_info.get('categorical_features', []):
                                    feature_type = 'categorical'
                                else:
                                    feature_type = 'numeric'

                                input_values[feature] = create_input_field(feature, feature_type, feature_info)
                    else:
                        # å¯¹äºè¾ƒå¤šç‰¹å¾ï¼Œä½¿ç”¨å¤šè¡Œæ˜¾ç¤º
                        num_rows = (len(features) + 2) // 3
                        for row in range(num_rows):
                            row_features = features[row * 3:(row + 1) * 3]
                            if row_features:
                                cols = st.columns(3)
                                for idx, feature in enumerate(row_features):
                                    with cols[idx]:
                                        if feature in feature_info.get('categorical_features', []):
                                            feature_type = 'categorical'
                                        else:
                                            feature_type = 'numeric'

                                        input_values[feature] = create_input_field(feature, feature_type, feature_info)

                # æäº¤æŒ‰é’®
                submitted = st.form_submit_button("ğŸ” å¼€å§‹é¢„æµ‹", use_container_width=True)

        # é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        with col2:
            st.header("ğŸ“Š é¢„æµ‹ç»“æœ")

            if submitted:
                with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                    # å‡†å¤‡è¾“å…¥æ•°æ® - ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½æœ‰å€¼
                    full_input_data = []
                    for feature in feature_info['feature_names']:
                        if feature in input_values:
                            full_input_data.append(input_values[feature])
                        else:
                            # å¯¹äºæœªè¾“å…¥çš„å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼
                            if feature in feature_info.get('categorical_features', []):
                                full_input_data.append(0)
                            else:
                                full_input_data.append(0.0)

                    # è¿›è¡Œé¢„æµ‹
                    probability, prediction = predict_single_patient(
                        full_input_data, model, scaler, median_imputer, mode_imputer, feature_info
                    )

                    if probability is not None:
                        # æ˜¾ç¤ºé£é™©æ¦‚ç‡
                        st.subheader("é£é™©è¯„ä¼°")

                        # åˆ›å»ºä»ªè¡¨ç›˜
                        fig, ax = plt.subplots(figsize=(8, 4))
                        risk_level = "é«˜é£é™©" if prediction == 1 else "ä½é£é™©"
                        colors = ['#FF4B4B', '#00D4AA']
                        color = colors[1] if prediction == 0 else colors[0]

                        ax.barh([0], [probability * 100], color=color, alpha=0.7)
                        ax.set_xlim(0, 100)
                        ax.set_xlabel('PDRé£é™©æ¦‚ç‡ (%)')
                        ax.set_yticks([])
                        ax.set_title(f'é£é™©æ¦‚ç‡: {probability * 100:.2f}%')

                        # æ·»åŠ é£é™©é˜ˆå€¼çº¿
                        ax.axvline(x=50, color='red', linestyle='--', alpha=0.5, label='é£é™©é˜ˆå€¼')
                        ax.legend()

                        st.pyplot(fig)

                        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                        st.metric(
                            label="é¢„æµ‹ç»“æœ",
                            value=risk_level,
                            delta=f"{probability * 100:.2f}%"
                        )

                        # æ˜¾ç¤ºä½¿ç”¨çš„ç‰¹å¾
                        with st.expander("ğŸ“‹ æœ¬æ¬¡é¢„æµ‹ä½¿ç”¨çš„ç‰¹å¾"):
                            used_features = []
                            for group_key in selected_groups:
                                used_features.extend(FEATURE_GROUPS[group_key]['features'])

                            st.write(f"**ä½¿ç”¨çš„ç‰¹å¾æ€»æ•°: {len(used_features)}**")
                            for i, feature in enumerate(used_features, 1):
                                st.write(f"{i}. {feature}")

                        # å»ºè®®ä¿¡æ¯
                        st.subheader("ğŸ’¡ å»ºè®®")
                        if prediction == 1:
                            st.error(
                                "âš ï¸ **é«˜é£é™©é¢„è­¦**:\n\n"
                                "â€¢ å»ºè®®ç«‹å³è¿›è¡Œè¯¦ç»†çœ¼ç§‘æ£€æŸ¥\n"
                                "â€¢ ä¸¥æ ¼æ§åˆ¶è¡€ç³–å’Œè¡€å‹\n"
                                "â€¢ å®šæœŸè¿›è¡Œçœ¼åº•æ£€æŸ¥\n"
                                "â€¢ éµåŒ»å˜±è¿›è¡Œå¿…è¦çš„æ²»ç–—å¹²é¢„"
                            )
                        else:
                            st.success(
                                "âœ… **ä½é£é™©æç¤º**:\n\n"
                                "â€¢ ç»§ç»­ä¿æŒè‰¯å¥½çš„è¡€ç³–æ§åˆ¶\n"
                                "â€¢ æ¯å¹´è¿›è¡Œä¸€æ¬¡çœ¼ç§‘æ£€æŸ¥\n"
                                "â€¢ ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼\n"
                                "â€¢ å¦‚å‡ºç°è§†åŠ›å˜åŒ–è¯·åŠæ—¶å°±åŒ»"
                            )

                        # å…è´£å£°æ˜
                        st.info(
                            "**å…è´£å£°æ˜**: æœ¬é¢„æµ‹ç»“æœåŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»å­¦è¯Šæ–­ã€‚å¦‚æœ‰ç–‘é—®ï¼Œè¯·å’¨è¯¢åŒ»ç–—ä¸“ä¸šäººå‘˜ã€‚"
                        )

            else:
                # é»˜è®¤æ˜¾ç¤ºç­‰å¾…ä¿¡æ¯
                st.info("è¯·åœ¨å·¦ä¾§å¡«å†™æ‚£è€…ä¿¡æ¯ï¼Œç„¶åç‚¹å‡»'å¼€å§‹é¢„æµ‹'æŒ‰é’®")

                # æ˜¾ç¤ºå½“å‰å±‚æ¬¡ä½¿ç”¨çš„ç‰¹å¾
                with st.expander("ğŸ“‹ å½“å‰å±‚æ¬¡å¯ç”¨çš„ç‰¹å¾"):
                    used_features = []
                    for group_key in selected_groups:
                        group = FEATURE_GROUPS[group_key]
                        st.write(f"**{group['name']}** ({len(group['features'])} ä¸ªç‰¹å¾):")
                        for i, feature in enumerate(group['features'], 1):
                            st.write(f"  {i}. {feature}")
                        used_features.extend(group['features'])

                    st.write(f"\n**æ€»ç‰¹å¾æ•°: {len(used_features)}**")

    else:  # æ‰¹é‡é¢„æµ‹æ¨¡å¼
        st.header("ğŸ“ æ‰¹é‡é¢„æµ‹")
        st.markdown(f"**å½“å‰åŒ»ç–—çº§åˆ«: {facility_level}**")

        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        if file_format == "Excel (.xlsx)":
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ æ‚£è€…æ•°æ®Excelæ–‡ä»¶",
                type=['xlsx', 'xls'],
                help="è¯·ç¡®ä¿Excelæ–‡ä»¶åŒ…å«å¿…è¦çš„ç‰¹å¾åˆ—ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å·¦ä¾§çš„æ¨¡æ¿æ–‡ä»¶ã€‚"
            )
        else:
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ æ‚£è€…æ•°æ®CSVæ–‡ä»¶",
                type=['csv'],
                help="è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å«å¿…è¦çš„ç‰¹å¾åˆ—ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å·¦ä¾§çš„æ¨¡æ¿æ–‡ä»¶ã€‚"
            )

        if uploaded_file is not None:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–æ•°æ®
                if uploaded_file.name.endswith(('.xlsx', '.xls')):
                    # è¯»å–Excelæ–‡ä»¶
                    batch_df = pd.read_excel(uploaded_file, engine='openpyxl')
                    st.success(f"âœ… æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼Œå…± {len(batch_df)} è¡Œæ•°æ®")
                else:
                    # è¯»å–CSVæ–‡ä»¶
                    batch_df = pd.read_csv(uploaded_file)
                    st.success(f"âœ… æˆåŠŸè¯»å–CSVæ–‡ä»¶ï¼Œå…± {len(batch_df)} è¡Œæ•°æ®")

                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                st.subheader("ğŸ“‹ æ•°æ®é¢„è§ˆ")
                st.write(f"æ•°æ®å½¢çŠ¶: {batch_df.shape[0]} è¡Œ Ã— {batch_df.shape[1]} åˆ—")

                # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                st.dataframe(batch_df.head(), use_container_width=True)

                # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
                with st.expander("ğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯"):
                    st.write("**æ•°å€¼å‹ç‰¹å¾ç»Ÿè®¡:**")
                    numeric_cols = batch_df.select_dtypes(include=[np.number]).columns
                    if len(numeric_cols) > 0:
                        st.dataframe(batch_df[numeric_cols].describe())
                    else:
                        st.write("æœªæ‰¾åˆ°æ•°å€¼å‹ç‰¹å¾")

                    st.write("**ç¼ºå¤±å€¼ç»Ÿè®¡:**")
                    missing_data = batch_df.isnull().sum()
                    missing_df = pd.DataFrame({
                        'ç‰¹å¾': missing_data.index,
                        'ç¼ºå¤±å€¼æ•°é‡': missing_data.values,
                        'ç¼ºå¤±ç‡ (%)': (missing_data.values / len(batch_df) * 100).round(2)
                    })
                    missing_df = missing_df[missing_df['ç¼ºå¤±å€¼æ•°é‡'] > 0]
                    if len(missing_df) > 0:
                        st.dataframe(missing_df)
                    else:
                        st.success("âœ… æ•°æ®å®Œæ•´ï¼Œæ— ç¼ºå¤±å€¼")

                # æ£€æŸ¥å¿…è¦çš„ç‰¹å¾
                required_features = []
                for group_key in selected_groups:
                    required_features.extend(FEATURE_GROUPS[group_key]['features'])

                missing_features = set(required_features) - set(batch_df.columns)
                if missing_features:
                    st.warning(f"âš ï¸ æ•°æ®ä¸­ç¼ºå°‘ä»¥ä¸‹å¿…è¦ç‰¹å¾: {list(missing_features)}")
                    st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶åŒ…å«æ‰€æœ‰å¿…è¦çš„ç‰¹å¾åˆ—ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å·¦ä¾§çš„æ¨¡æ¿æ–‡ä»¶ã€‚")

                else:
                    # å¼€å§‹æ‰¹é‡é¢„æµ‹æŒ‰é’®
                    if st.button("ğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹", type="primary", use_container_width=True):
                        with st.spinner(f"æ­£åœ¨å¯¹ {len(batch_df)} åæ‚£è€…è¿›è¡Œé¢„æµ‹..."):
                            # æ‰§è¡Œæ‰¹é‡é¢„æµ‹
                            results_df = batch_predict(
                                batch_df, model, feature_info, median_imputer, mode_imputer, scaler, selected_features
                            )

                            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                            st.subheader("ğŸ“Š æ‰¹é‡é¢„æµ‹ç»“æœ")

                            # ç»Ÿè®¡ä¿¡æ¯
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("æ‚£è€…æ€»æ•°", len(results_df))
                            with col2:
                                high_risk_count = (results_df['PDRé¢„æµ‹æ¦‚ç‡'] > 0.7).sum()
                                st.metric("é«˜é£é™©æ‚£è€…", high_risk_count)
                            with col3:
                                medium_risk_count = ((results_df['PDRé¢„æµ‹æ¦‚ç‡'] >= 0.3) & (
                                            results_df['PDRé¢„æµ‹æ¦‚ç‡'] <= 0.7)).sum()
                                st.metric("ä¸­é£é™©æ‚£è€…", medium_risk_count)
                            with col4:
                                low_risk_count = (results_df['PDRé¢„æµ‹æ¦‚ç‡'] < 0.3).sum()
                                st.metric("ä½é£é™©æ‚£è€…", low_risk_count)

                            # é£é™©åˆ†å¸ƒå›¾
                            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

                            # é£é™©ç­‰çº§åˆ†å¸ƒ
                            risk_counts = results_df['PDRé£é™©ç­‰çº§'].value_counts()
                            colors = ['#00D4AA', '#FFA500', '#FF4B4B']  # ç»¿ã€æ©™ã€çº¢
                            ax1.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%',
                                    colors=colors[:len(risk_counts)], startangle=90)
                            ax1.set_title('é£é™©ç­‰çº§åˆ†å¸ƒ')

                            # é£é™©æ¦‚ç‡åˆ†å¸ƒç›´æ–¹å›¾
                            ax2.hist(results_df['PDRé¢„æµ‹æ¦‚ç‡'], bins=20, edgecolor='black', alpha=0.7,
                                     color='steelblue')
                            ax2.axvline(x=0.3, color='orange', linestyle='--', label='ä½/ä¸­é£é™©é˜ˆå€¼')
                            ax2.axvline(x=0.7, color='red', linestyle='--', label='ä¸­/é«˜é£é™©é˜ˆå€¼')
                            ax2.set_xlabel('PDRé£é™©æ¦‚ç‡')
                            ax2.set_ylabel('æ‚£è€…æ•°é‡')
                            ax2.set_title('é£é™©æ¦‚ç‡åˆ†å¸ƒ')
                            ax2.legend()
                            ax2.grid(alpha=0.3)

                            plt.tight_layout()
                            st.pyplot(fig)

                            # é«˜é£é™©æ‚£è€…è¯¦æƒ…
                            high_risk_df = results_df[results_df['PDRé£é™©ç­‰çº§'] == 'é«˜é£é™©']
                            if not high_risk_df.empty:
                                st.warning(f"âš ï¸ **å‘ç° {len(high_risk_df)} åé«˜é£é™©æ‚£è€…**")
                                with st.expander("ğŸ”´ é«˜é£é™©æ‚£è€…è¯¦æƒ…"):
                                    st.dataframe(high_risk_df, use_container_width=True)

                            # æ˜¾ç¤ºç»“æœè¡¨æ ¼
                            st.subheader("ğŸ“‹ è¯¦ç»†é¢„æµ‹ç»“æœ")

                            # æ·»åŠ ç­›é€‰åŠŸèƒ½
                            st.markdown("**ç­›é€‰é¢„æµ‹ç»“æœ:**")
                            filter_col1, filter_col2 = st.columns(2)
                            with filter_col1:
                                risk_filter = st.selectbox(
                                    "æŒ‰é£é™©ç­‰çº§ç­›é€‰:",
                                    ["å…¨éƒ¨", "é«˜é£é™©", "ä¸­é£é™©", "ä½é£é™©"]
                                )
                            with filter_col2:
                                probability_filter = st.slider(
                                    "æŒ‰é¢„æµ‹æ¦‚ç‡ç­›é€‰:",
                                    0.0, 1.0, (0.0, 1.0), 0.01
                                )

                            # åº”ç”¨ç­›é€‰
                            filtered_df = results_df.copy()
                            if risk_filter != "å…¨éƒ¨":
                                filtered_df = filtered_df[filtered_df['PDRé£é™©ç­‰çº§'] == risk_filter]
                            filtered_df = filtered_df[
                                (filtered_df['PDRé¢„æµ‹æ¦‚ç‡'] >= probability_filter[0]) &
                                (filtered_df['PDRé¢„æµ‹æ¦‚ç‡'] <= probability_filter[1])
                                ]

                            st.write(f"ç­›é€‰ç»“æœ: {len(filtered_df)} åæ‚£è€…")
                            st.dataframe(filtered_df, use_container_width=True)

                            # ä¸‹è½½æŒ‰é’®
                            st.markdown("### ğŸ’¾ ä¸‹è½½ç»“æœ")
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

                            # æä¾›å¤šç§æ ¼å¼ä¸‹è½½
                            col1, col2 = st.columns(2)
                            with col1:
                                # Excelæ ¼å¼ä¸‹è½½
                                excel_filename = f"pdré¢„æµ‹ç»“æœ_{timestamp}.xlsx"
                                st.markdown(get_table_download_link(results_df, excel_filename, "excel"),
                                            unsafe_allow_html=True)
                            with col2:
                                # CSVæ ¼å¼ä¸‹è½½
                                csv_filename = f"pdré¢„æµ‹ç»“æœ_{timestamp}.csv"
                                st.markdown(get_table_download_link(results_df, csv_filename, "csv"),
                                            unsafe_allow_html=True)

                            # å•ç‹¬ä¸‹è½½é«˜é£é™©æ‚£è€…
                            if not high_risk_df.empty:
                                st.markdown("#### ğŸ”´ é«˜é£é™©æ‚£è€…å•ç‹¬ä¸‹è½½")
                                high_risk_filename = f"pdré«˜é£é™©æ‚£è€…_{timestamp}.xlsx"
                                st.markdown(get_table_download_link(high_risk_df, high_risk_filename, "excel"),
                                            unsafe_allow_html=True)

            except Exception as e:
                st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                if uploaded_file.name.endswith(('.xlsx', '.xls')):
                    st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„Excelæ ¼å¼ï¼Œä¸”åŒ…å«æ­£ç¡®çš„åˆ—åã€‚")
                else:
                    st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„CSVæ ¼å¼ï¼Œä¸”åŒ…å«æ­£ç¡®çš„åˆ—åã€‚")

        else:
            # æ˜¾ç¤ºæ‰¹é‡é¢„æµ‹è¯´æ˜
            st.info(f"""
            ## ğŸ“ æ‰¹é‡é¢„æµ‹ä½¿ç”¨è¯´æ˜ (ä½¿ç”¨{file_format})

            1. **ä¸‹è½½æ¨¡æ¿**: åœ¨å·¦ä¾§è¾¹æ ä¸‹è½½{file_format}æ¨¡æ¿
            2. **å¡«å†™æ•°æ®**: åœ¨æ¨¡æ¿ä¸­å¡«å†™æ‚£è€…ä¿¡æ¯ï¼ˆå¯å¡«å†™å¤šåæ‚£è€…ï¼‰
            3. **ä¸Šä¼ æ–‡ä»¶**: ä½¿ç”¨ä¸Šæ–¹æ–‡ä»¶ä¸Šä¼ å™¨ä¸Šä¼ {file_format}æ–‡ä»¶
            4. **å¼€å§‹é¢„æµ‹**: ç‚¹å‡»"å¼€å§‹æ‰¹é‡é¢„æµ‹"æŒ‰é’®
            5. **æŸ¥çœ‹ç»“æœ**: æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯ã€å¯è§†åŒ–å›¾è¡¨å’Œè¯¦ç»†ç»“æœ
            6. **ä¸‹è½½ç»“æœ**: é¢„æµ‹å®Œæˆåä¸‹è½½ç»“æœæ–‡ä»¶

            ### ğŸ“‹ æ•°æ®è¦æ±‚
            - {file_format}æ ¼å¼æ–‡ä»¶
            - åŒ…å«å¿…è¦çš„ç‰¹å¾åˆ—ï¼ˆæ ¹æ®å½“å‰åŒ»ç–—çº§åˆ«ï¼‰
            - æ•°å€¼å‹ç‰¹å¾å¡«å†™æ•°å­—
            - åˆ†ç±»ç‰¹å¾å¡«å†™0æˆ–1ï¼ˆå¦‚æ€§åˆ«ï¼š1=ç”·ï¼Œ0=å¥³ï¼‰

            ### âš ï¸ æ³¨æ„äº‹é¡¹
            - ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ç¼ºå¤±å€¼
            - ç¡®ä¿ç‰¹å¾å•ä½ä¸æ¨¡æ¿ä¸€è‡´
            - é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šè¯Šæ–­
            """)

    # åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: gray;'>"
        "åŸºäºLightGBMæœºå™¨å­¦ä¹ æ¨¡å‹ | ä»…ä¾›åŒ»ç–—ä¸“ä¸šäººå‘˜å‚è€ƒ"
        "</div>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()